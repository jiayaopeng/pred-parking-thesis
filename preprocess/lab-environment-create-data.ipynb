{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d260ab0",
   "metadata": {},
   "source": [
    "# Create all datasets required for creating a Version 3 ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1a2ea",
   "metadata": {},
   "source": [
    "## This notebook sets up datasets required for building features and models out of PayByPhone frontend data as well as all data to measure performance in Seattle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b6256",
   "metadata": {},
   "source": [
    "## Data preparation for version 3: street-booking assignment \n",
    "We perform the following steps in each city in version 3, it's done for Seattle only in this notebook:\n",
    "\n",
    "1. Extract street network in Seattle using Open Street Map API. Each street gets assigned a unique id\n",
    "2. Read booking events using PaybyPhone (PBP) frontend data \n",
    "3. Assign each booking event to a street (infer where the user is parking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70333a",
   "metadata": {},
   "source": [
    "## Seattle data preparation for evaluation\n",
    "We perform additional Seattle-specific steps for evaluation purposes:\n",
    "\n",
    "1. Load geometries from PBP location identifiers\n",
    "2. Create mapping between PBP locations and streets (usually one street covers 1-4 PBP locations)\n",
    "3. Evaluate our assignment rule from step 3 od data preparation fpr version 3 (above) using the identifiers\n",
    "4. Load the Seattle ground truth dataset sampled by the Departement of Transportation\n",
    "5. Create ground-truth lables for the street network based on Seattle ground-truth data (only if all corresponding PBP locations are occupied the whole street is also occupied, if one location is free, the street is free)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af6e2e",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "As of August 26th, 2021, this notebook has been run partially to generate data for more radiuses(namely adding radius for 25, 50, and previous added 100, 150, 250) in contrast to 500 radius as before. Since it has been run partially, below points needed to be noted:\n",
    "\n",
    "   1. It was found in this current run where we query open street again, for the 6 radius, the no. of POI in certain radius has changed greatly(eg. residential of 500 m radius changed from tens to thousands, which does not reflect closely to the real world situation, however, we could not find out why it has changed, therefore we take the current data as it is with the information in mind that open street map might have changed the tags of the POIs) -- One solution could be install fixed version of open street map, and there are two releases in May 2021, since the first time of querying the POI result.\n",
    "   \n",
    "   2. There are sections which are run paritally(only first section) just to use the old data merge with new queried result for new radiuses, so please do not run those section when you are generating new data all over again.\n",
    "   \n",
    "   3. There are multiple reasons why we decide to run the notebook partially and merge the new data with old data:\n",
    "       1) save time\n",
    "       2) at the line *label_df = label_df.merge(streets[different_radius_cols].astype(str).drop_duplicates(), on='street_id')*, it was found the current queried geometry from OSM even generate less overlapping compared to the geometry of the ground truth data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0eeb7",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install OSMNX\n",
    "!pip install folium\n",
    "!pip install pyprobar  # progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed6758",
   "metadata": {},
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import geopandas as gpd\n",
    "import osmnx as ox \n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely import wkt\n",
    "\n",
    "import warnings\n",
    "from pyprobar import bar, probar\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "\n",
    "from groundtruth_helper import  compute_gt_labels\n",
    "\n",
    "import geolocation_helper\n",
    "import openstreetmap_helper #import print_pbp_locations_on_map, retrieve_pois, cluster_pois, merge_pois_with_street_network\n",
    "\n",
    "importlib.reload(openstreetmap_helper) # reload only module\n",
    "importlib.reload(geolocation_helper)\n",
    "\n",
    "from openstreetmap_helper import *\n",
    "from geolocation_helper import merge_df_on_nearest_geometries, define_circle_around_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read global configuration details\n",
    "with open('sagemaker_config_v3.json') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client= boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c925808",
   "metadata": {},
   "source": [
    "## Merge the Newly Queried Radius with Previous Dataset(As Alternative to Below Sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ab0c4",
   "metadata": {},
   "source": [
    "NOTE: it seems that open street map has changed the tags, because for a radius 500, the number of POIs in each category has increased greatly and as of August 16, 2021, since the querying, open street map has generated 2 major releases in May. To avoid the weird POI count in the radius, we might want to only install a fixed version of open street map before the May releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c234dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_final = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different_radius_seattle_groundtruth_labels_with_openstreetmap_features.csv', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f043fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_final['geometry'] = original_final['geometry'].apply(wkt.loads)\n",
    "original_final=gpd.GeoDataFrame(original_final, geometry = original_final.geometry).set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "include_radius_25 = merge_pois_with_final_result(street_network=original_final, pois=pois_seattle_filtered, radius=25)\n",
    "include_radius_25.to_csv('include_radius_25_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "include_radius_50 = merge_pois_with_final_result(street_network=original_final, pois=pois_seattle_filtered, radius=50)\n",
    "include_radius_50.to_csv('include_radius_50_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "include_radius_100 = merge_pois_with_final_result(street_network=original_final, pois=pois_seattle_filtered, radius=100)\n",
    "include_radius_100.to_csv('include_radius_100_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "include_radius_150 = merge_pois_with_final_result(street_network=original_final, pois=pois_seattle_filtered, radius=150)\n",
    "include_radius_150.to_csv('include_radius_150_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f58973",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "include_radius_250 = merge_pois_with_final_result(street_network=original_final, pois=pois_seattle_filtered, radius=250)\n",
    "include_radius_250.to_csv('include_radius_250_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51961fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "include_radius_500 = merge_pois_with_final_result(street_network=original_final, pois=pois_seattle_filtered, radius=500)\n",
    "include_radius_500.to_csv('include_radius_500_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0803933",
   "metadata": {},
   "source": [
    "#### Upload the Raw Queried Data to S3\n",
    "Raw query is the dataframe which directly coming open street map and where we did not change the name of the column, just to save it in case there is a bug later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86245144",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['include_radius_25_raw.csv', 'include_radius_50_raw.csv', \n",
    "         'include_radius_100_raw.csv', 'include_radius_150_raw.csv',\n",
    "         'include_radius_250_raw.csv', 'include_radius_500_raw.csv']\n",
    "\n",
    "for file in files:\n",
    "    print(f'uploading {file} to object input/processed/frontend/different-radius-intermediate/{file} in s3')\n",
    "    client.upload_file(f'{file}', 'bucket-vwfs-pred-park-global-model-serving-dev', f'input/processed/frontend/different-radius-intermediate/{file}')\n",
    "    print(f'{file} upload finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_radius_25 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different-radius-intermediate/include_radius_25_raw.csv', index_col=0)\n",
    "include_radius_50 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different-radius-intermediate/include_radius_50_raw.csv', index_col=0)\n",
    "include_radius_100 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different-radius-intermediate/include_radius_100_raw.csv', index_col=0)\n",
    "include_radius_150 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different-radius-intermediate/include_radius_150_raw.csv', index_col=0)\n",
    "include_radius_250 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different-radius-intermediate/include_radius_250_raw.csv',index_col=0)\n",
    "include_radius_500 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/processed/frontend/different-radius-intermediate/include_radius_500_raw.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_radius = {'include_radius_25': include_radius_25,\n",
    "          'include_radius_50': include_radius_50, \n",
    "          'include_radius_100': include_radius_100, \n",
    "          'include_radius_150':include_radius_150, \n",
    "          'include_radius_250':include_radius_250, \n",
    "          'include_radius_500':include_radius_500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ec80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original radius 100, 150, 250, 500\n",
    "for key, value in dict_df_radius.items():\n",
    "    value.drop([\"commercial_100\", \"residential_100\", \"transportation_100\", \"schools_100\", \"eventsites_100\",\n",
    "                \"commercial_150\", \"residential_150\", \"transportation_150\", \"schools_150\", \"eventsites_150\", \n",
    "                \"commercial_250\", \"residential_250\", \"transportation_250\", \"schools_250\", \"eventsites_250\",\n",
    "                 \"commercial_500\", \"residential_500\", \"transportation_500\", \"schools_500\", \"eventsites_500\"], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202679f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df, name):\n",
    "    df.rename(\n",
    "        columns = {\n",
    "            'commercial': f'commercial_{name}',\n",
    "            'residential': f'residential_{name}',\n",
    "            'transportation': f'transportation_{name}',\n",
    "            'schools': f'schools_{name}',\n",
    "            'eventsites': f'eventsites_{name}'\n",
    "        }\n",
    ")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0dc334",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_radius.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_radius['include_radius_25'] = rename_cols(dict_df_radius['include_radius_25'], 25)\n",
    "dict_df_radius['include_radius_50'] = rename_cols(dict_df_radius['include_radius_50'], 50)\n",
    "dict_df_radius['include_radius_100'] = rename_cols(dict_df_radius['include_radius_100'], 100)\n",
    "dict_df_radius['include_radius_150'] = rename_cols(dict_df_radius['include_radius_150'], 150)\n",
    "dict_df_radius['include_radius_250'] = rename_cols(dict_df_radius['include_radius_250'], 250)\n",
    "dict_df_radius['include_radius_500'] = rename_cols(dict_df_radius['include_radius_500'], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_df_radius.items():\n",
    "    value.to_csv(key + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload separate files to s3\n",
    "files = ['include_radius_25.csv', 'include_radius_50.csv', \n",
    "         'include_radius_100.csv', 'include_radius_150.csv',\n",
    "         'include_radius_250.csv', 'include_radius_500.csv']\n",
    "\n",
    "for file in files:\n",
    "    print(f'uploading {file} to object input/processed/frontend/different-radius-intermediate/{file} in s3')\n",
    "    client.upload_file(f'{file}', 'bucket-vwfs-pred-park-global-model-serving-dev', f'input/processed/frontend/different-radius-intermediate/{file}')\n",
    "    print(f'{file} upload finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870071b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the street data from s3 for different radius\n",
    "ls_files = ['include_radius_25', 'include_radius_50', \n",
    "          'include_radius_100', 'include_radius_150',\n",
    "          'include_radius_250', 'include_radius_500']\n",
    "include_radius_data = {}\n",
    "for file in ls_files:\n",
    "    csv_obj = client.get_object(Bucket=config.get(\"global\").get(\"s3_bucket\"), \n",
    "                                Key=f'input/processed/frontend/different-radius-intermediate/{file}.csv')\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    read_include_radius = pd.read_csv(io.StringIO(csv_string), index_col=0)\n",
    "    include_radius_data[file] = read_include_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = include_radius_data['include_radius_25'].drop([\"commercial_25\", \"residential_25\", \"transportation_25\", \"schools_25\", \"eventsites_25\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding it all together\n",
    "list_df = [base,\n",
    "           include_radius_data['include_radius_25'][[\"commercial_25\", \"residential_25\", \"transportation_25\", \"schools_25\", \"eventsites_25\"]], \n",
    "           include_radius_data['include_radius_50'][[\"commercial_50\", \"residential_50\", \"transportation_50\", \"schools_50\", \"eventsites_50\"]], \n",
    "           include_radius_data['include_radius_100'][[\"commercial_100\", \"residential_100\", \"transportation_100\", \"schools_100\", \"eventsites_100\"]], \n",
    "           include_radius_data['include_radius_150'][[\"commercial_150\", \"residential_150\", \"transportation_150\", \"schools_150\", \"eventsites_150\"]], \n",
    "           include_radius_data['include_radius_250'][[\"commercial_250\", \"residential_250\", \"transportation_250\", \"schools_250\", \"eventsites_250\"]], \n",
    "           include_radius_data['include_radius_500'][[\"commercial_500\", \"residential_500\", \"transportation_500\", \"schools_500\", \"eventsites_500\"]], \n",
    "          ]\n",
    "different_radius_6_radius_seattle_groundtruth_labels_with_openstreetmap_features = pd.concat(list_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e69bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_6_radius_seattle_groundtruth_labels_with_openstreetmap_features.to_csv('different_radius_6_radius_seattle_groundtruth_labels_with_openstreetmap_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to s3 -- this is now the final file from this notebook\n",
    "\n",
    "client.upload_file('different_radius_6_radius_seattle_groundtruth_labels_with_openstreetmap_features.csv', 'bucket-vwfs-pred-park-global-model-serving-dev',\n",
    "                   'input/processed/frontend/different_radius_6_radius_seattle_groundtruth_labels_with_openstreetmap_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a51f4",
   "metadata": {},
   "source": [
    "## Get Street Network from Seattle using open street maps(Query All New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = \"Seattle, US\"\n",
    "graph = ox.graph_from_place(place_name, network_type='drive')\n",
    "streets = ox.utils_graph.graph_to_gdfs(ox.get_undirected(graph), nodes=False)\n",
    "\n",
    "# if nodes=True: streets[0]: intersections (=nodes), streets[1]: streets (=edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03fc19",
   "metadata": {},
   "source": [
    "### Get POIs from Open Street Map \n",
    "\n",
    "This gets the new data from open street map as alternative compared to below where we merge with old already queried data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve POIs--only run when needed!\n",
    "pois_seattle = retrieve_pois(place_name=place_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster POIs--only run when needed! one radius will generate about 5000 api call\n",
    "pois_seattle_filtered = cluster_pois(pois_seattle) # this line need to be ran for each query\n",
    "# merge POIs with street network and calculate the number of POIs in a given radius around every street\n",
    "streets_25 = merge_pois_with_street_network(street_network=streets, pois=pois_seattle_filtered, radius=25)\n",
    "# save the data--only run when needed!\n",
    "streets_25.to_csv('different_radius_streets_25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "streets_50 = merge_pois_with_street_network(street_network=streets, pois=pois_seattle_filtered, radius=50)\n",
    "streets_50.to_csv('different_radius_streets_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "streets_100 = merge_pois_with_street_network(street_network=streets, pois=pois_seattle_filtered, radius=100)\n",
    "streets_100.to_csv('different_radius_streets_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "streets_150 = merge_pois_with_street_network(street_network=streets, pois=pois_seattle_filtered, radius=150)\n",
    "streets_150.to_csv('different_radius_streets_150.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "streets_250 = merge_pois_with_street_network(street_network=streets, pois=pois_seattle_filtered, radius=250)\n",
    "streets_250.to_csv('different_radius_streets_250.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_seattle_filtered = cluster_pois(pois_seattle)\n",
    "streets_500 = merge_pois_with_street_network(street_network=streets, pois=pois_seattle_filtered, radius=500)\n",
    "streets_500.to_csv('different_radius_streets_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc01c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload separate files to s3\n",
    "files = ['different_radius_streets_25.csv', 'different_radius_streets_50.csv', \n",
    "         'different_radius_streets_100.csv', 'different_radius_streets_150.csv',\n",
    "         'different_radius_streets_250.csv', 'different_radius_streets_500.csv']\n",
    "\n",
    "for file in files:\n",
    "    print(f'uploading {file} to object input/processed/frontend/{file} in s3')\n",
    "    client.upload_file(f'{file}', 'bucket-vwfs-pred-park-global-model-serving-dev', f'input/processed/frontend/{file}')\n",
    "    print(f'{file} upload finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53133fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the street data from s3 for different radius\n",
    "client = boto3.client('s3')\n",
    "ls_files = ['radius_25_filename','radius_50_filename',\n",
    "            'radius_100_filename', 'radius_150_filename',\n",
    "            'radius_250_filename', 'radius_500_filename']\n",
    "radius_data = {}\n",
    "for file in ls_files:\n",
    "    csv_obj = client.get_object(Bucket=config.get(\"global\").get(\"s3_bucket\"), \n",
    "                                Key=config.get(\"development\").get(file))\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    read_radius = pd.read_csv(io.StringIO(csv_string))\n",
    "    radius_data[file] = read_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_trans = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/open_data/seattle/train_data_with_trans.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d0fac",
   "metadata": {},
   "source": [
    "### Assign unique id to each street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14310bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we merge the data from first run to current df to get all the columns\n",
    "for key, df in radius_data.items():\n",
    "    radius_data[key] = pd.merge(df, train_data_with_trans[['geometry', 'street_id', 'study_area', 'ongoing_trans']].astype(str) ,on ='geometry', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee071537",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of streets 100 and save it to streets as ground truth\n",
    "streets = radius_data['radius_100_filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e30dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename of the columns\n",
    "streets.rename(\n",
    "    columns={\"commercial\": \"commercial_100\", \n",
    "             \"residential\": \"residential_100\",\n",
    "             \"transportation\":\"transportation_100\",\n",
    "             \"schools\": \"schools_100\",\n",
    "             \"eventsites\": \"eventsites_100\"\n",
    "            },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e702629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "streets_150 = radius_data['radius_150_filename'][[\"commercial\", \"residential\", \"transportation\", \"schools\", \"eventsites\"]]\n",
    "streets_250 = radius_data['radius_250_filename'][[\"commercial\", \"residential\", \"transportation\", \"schools\", \"eventsites\"]]\n",
    "streets_500 = radius_data['radius_500_filename'][[\"commercial\", \"residential\", \"transportation\", \"schools\", \"eventsites\"]]\n",
    "streets_25 = radius_data['radius_25_filename'][[\"commercial\", \"residential\", \"transportation\", \"schools\", \"eventsites\"]]\n",
    "streets_50 = radius_data['radius_50_filename'][[\"commercial\", \"residential\", \"transportation\", \"schools\", \"eventsites\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename other columns for other radius\n",
    "streets_150 = streets_150.rename(\n",
    "    columns={\"commercial\": \"commercial_150\", \n",
    "             \"residential\": \"residential_150\",\n",
    "             \"transportation\":\"transportation_150\",\n",
    "             \"schools\": \"schools_150\",\n",
    "             \"eventsites\": \"eventsites_150\"\n",
    "            }\n",
    ")\n",
    "\n",
    "streets_250 = streets_250.rename(\n",
    "    columns={\"commercial\": \"commercial_250\", \n",
    "             \"residential\": \"residential_250\",\n",
    "             \"transportation\":\"transportation_250\",\n",
    "             \"schools\": \"schools_250\",\n",
    "             \"eventsites\": \"eventsites_250\"\n",
    "            }\n",
    ")\n",
    "\n",
    "streets_500 = streets_500.rename(\n",
    "    columns={\"commercial\": \"commercial_500\", \n",
    "             \"residential\": \"residential_500\",\n",
    "             \"transportation\":\"transportation_500\",\n",
    "             \"schools\": \"schools_500\",\n",
    "             \"eventsites\": \"eventsites_500\"\n",
    "            }\n",
    ")\n",
    "\n",
    "streets_25 = streets_25.rename(\n",
    "    columns={\"commercial\": \"commercial_25\", \n",
    "             \"residential\": \"residential_25\",\n",
    "             \"transportation\":\"transportation_25\",\n",
    "             \"schools\": \"schools_25\",\n",
    "             \"eventsites\": \"eventsites_25\"\n",
    "            }\n",
    ")\n",
    "\n",
    "\n",
    "streets_50 = streets_50.rename(\n",
    "    columns={\"commercial\": \"commercial_50\", \n",
    "             \"residential\": \"residential_50\",\n",
    "             \"transportation\":\"transportation_50\",\n",
    "             \"schools\": \"schools_50\",\n",
    "             \"eventsites\": \"eventsites_50\"\n",
    "            }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the different radius together\n",
    "list_df = [streets, \n",
    "           streets_150[[\"commercial_150\", \"residential_150\", \"transportation_150\", \"schools_150\", \"eventsites_150\"]], \n",
    "           streets_250[[\"commercial_250\", \"residential_250\", \"transportation_250\", \"schools_250\", \"eventsites_250\"]], \n",
    "           streets_500[[\"commercial_500\", \"residential_500\", \"transportation_500\", \"schools_500\", \"eventsites_500\"]],\n",
    "           streets_25[[\"commercial_25\", \"residential_25\", \"transportation_25\", \"schools_25\", \"eventsites_25\"]], \n",
    "           streets_50[[\"commercial_50\", \"residential_50\", \"transportation_50\", \"schools_50\", \"eventsites_50\"]], \n",
    "          ]\n",
    "streets = pd.concat(list_df, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935b437",
   "metadata": {},
   "source": [
    "### Prep streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5decf9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for different radius\n",
    "# reset index \n",
    "streets.set_index(['u', 'v'], inplace=True)\n",
    "\n",
    "# geo_df\n",
    "streets['geometry'] = streets['geometry'].apply(wkt.loads)\n",
    "streets = gpd.GeoDataFrame(streets, geometry=streets.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfe777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for only 500 meter radius\n",
    "\n",
    "streets_500_only = streets.drop([\"commercial_100\", \"residential_100\", \"transportation_100\", \"schools_100\", \"eventsites_100\",\n",
    "                                \"commercial_150\", \"residential_150\", \"transportation_150\", \"schools_150\", \"eventsites_150\", \n",
    "                                \"commercial_250\", \"residential_250\", \"transportation_250\", \"schools_250\", \"eventsites_250\",\n",
    "                                 \"commercial_25\", \"residential_25\", \"transportation_25\", \"schools_25\", \"eventsites_25\",\n",
    "                                 \"commercial_50\", \"residential_50\", \"transportation_50\", \"schools_50\", \"eventsites_50\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71aa58f",
   "metadata": {},
   "source": [
    "## Read frontend data from PBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "client= boto3.client('s3')\n",
    "csv_obj = client.get_object(Bucket=config.get(\"global\").get(\"s3_bucket\"), Key=config.get(\"development\").get(\"paybyphone_frontend_data_filename\"))\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "\n",
    "seattle = pd.read_csv(io.StringIO(csv_string),dtype={'vendorId': str, 'adLocationId':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358b7dd",
   "metadata": {},
   "source": [
    "### Use only vendorId 4661 (=Seattle) and parking start and extend events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle = seattle[seattle.vendorId==\"4661\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking = gpd.GeoDataFrame(\n",
    "    seattle, geometry=gpd.points_from_xy(seattle.long, seattle.lat))\n",
    "parking = parking.loc[parking.action.isin(['PARKING_START','PARKING_EXTEND'])]\n",
    "parking = parking.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047bd82",
   "metadata": {},
   "source": [
    "### Convert types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking.advLocationId = parking.advLocationId.astype(str)\n",
    "#use utc times\n",
    "parking.created = pd.to_datetime(parking.created, unit='ms')\n",
    "parking.expires = pd.to_datetime(parking.expires).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c64f80",
   "metadata": {},
   "source": [
    "### Append assigned street id and information about that street to the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ac90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign for the data with different radius\n",
    "parking_with_assign = merge_df_on_nearest_geometries(parking, streets, gdfB_cols=config.get(\"development\").get(\"different_radius_street_columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d84933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign for the data with only 500 meters as radius \n",
    "# rename the column back\n",
    "streets_500_only = streets_500_only.rename(\n",
    "    columns={\"commercial_500\": \"commercial\", \n",
    "             \"residential_500\": \"residential\",\n",
    "             \"transportation_500\": \"transportation\",\n",
    "              \"schools_500\": \"schools\",\n",
    "             \"eventsites_500\": \"eventsites\" \n",
    "            }\n",
    ")\n",
    "parking_with_assign_500_only = merge_df_on_nearest_geometries(parking, streets_500_only, gdfB_cols=config.get(\"development\").get(\"street_columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610090b6",
   "metadata": {},
   "source": [
    "## We now assigned each transaction to a street. The following code is to enable seattle specific evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b6f45",
   "metadata": {},
   "source": [
    "### To check the accuracy of the assignemnt we need the information whether the assigend street id correponds to the locationId of the ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f6b74",
   "metadata": {},
   "source": [
    "### Read the geometry of the location identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_location_geometries = gpd.read_file('s3://{}/{}'.format(config.get(\"global\").get(\"s3_bucket\"), config.get(\"development\").get(\"paybyphone_location_geometries_filename\"))).set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fc2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = merge_df_on_nearest_geometries(pbp_location_geometries, streets)\n",
    "mapping = mapping.groupby('street_id').apply(lambda x: x.advLocationId.unique()).reset_index(name='assigned_gt_location_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f496a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different radius merge mapping\n",
    "parking_with_assign = parking_with_assign.merge(mapping, on='street_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d71f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original 500 radius merge mapping\n",
    "parking_with_assign_500_only = parking_with_assign_500_only.merge(mapping, on='street_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388b78a",
   "metadata": {},
   "source": [
    "### Save data for modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result for different radius\n",
    "parking_with_assign.to_csv(\"different_radius_\" + config.get(\"development\").get(\"parking_and_streets_filename\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result for original 500 radius only\n",
    "parking_with_assign_500_only.to_csv(\"new_\" + config.get(\"development\").get(\"parking_and_streets_filename\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the different radius\n",
    "client.upload_file(\"different_radius_parking_frontend_data_assigned.csv\", config.get(\"global\").get(\"s3_bucket\"), \"input/processed/frontend/different_radius_{}\".format(config.get(\"development\").get(\"parking_and_streets_filename\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the 500 radius\n",
    "client.upload_file(\"new_parking_frontend_data_assigned.csv\", config.get(\"global\").get(\"s3_bucket\"), \"input/processed/frontend/new_{}\".format(config.get(\"development\").get(\"parking_and_streets_filename\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350de62",
   "metadata": {},
   "source": [
    "### Check accuracy of assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy for different radius\n",
    "np.mean([x.advLocationId in x.assigned_gt_location_ids for _,x in parking_with_assign.iterrows() if x.action=='PARKING_START'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy for 500 radius\n",
    "np.mean([x.advLocationId in x.assigned_gt_location_ids for _,x in parking_with_assign_500_only.iterrows() if x.action=='PARKING_START'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8238cc",
   "metadata": {},
   "source": [
    "## Prepare ground-truth data from Seattle Departement of Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ee90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "csv_obj = client.get_object(Bucket=config.get(\"global\").get(\"s3_bucket\"), Key=config.get(\"development\").get(\"seattle_groundtruth_filename\"))\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "\n",
    "parking_study = pd.read_csv(io.StringIO(csv_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bae0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_study.rename({'elmntkey':'advLocationId'},axis=1, inplace=True)\n",
    "parking_study.advLocationId = parking_study.advLocationId.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3d589",
   "metadata": {},
   "source": [
    "### Use only observations of times for which we have PayByPhone transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_study.time_stamp = pd.to_datetime(parking_study.time_stamp)\n",
    "parking_study.date_time = pd.to_datetime(parking_study.date_time)\n",
    "time_stamp_date_only_mask = parking_study.time_stamp.map(lambda x: x.strftime(\"%H:%M\"))==\"00:00\"\n",
    "parking_study.time_stamp[time_stamp_date_only_mask]=parking_study[time_stamp_date_only_mask].date_time\n",
    "parking_study = parking_study[parking_study.time_stamp>=parking.created.min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c63e34",
   "metadata": {},
   "source": [
    "### Compute labels based on our own parking zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a433b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_study = parking_study.merge(pbp_location_geometries[[\"advLocationId\", \"geometry\"]], on=\"advLocationId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465284f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label df, note here we use streets for both different radius case and 500 radius case, because they generate same result\n",
    "label_df = compute_gt_labels(pred_geom=streets, groundtruth_data=gpd.GeoDataFrame(parking_study_merged_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_df.droplevel(2).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb3eb3",
   "metadata": {},
   "source": [
    "### Add street features (we do it here since we do not want to reload the street df later) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for different radius\n",
    "different_radius_cols = config.get(\"development\").get(\"different_radius_street_columns\")\n",
    "different_radius_cols.insert(4, \"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for 500 radius\n",
    "cols = config.get(\"development\").get(\"street_columns\")\n",
    "cols.insert(4, \"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ce338",
   "metadata": {},
   "source": [
    "NOTE: below merge need to be checked if we run this notebook again, as currently it yields inconsistent merge result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245510d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should we really use \"astype(str)\" here as some variables are numbers?\n",
    "label_df = label_df.merge(streets[different_radius_cols].astype(str).drop_duplicates(), on='street_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.maxspeed = [ x.split(' ')[0] for x in label_df.maxspeed.tolist() ]  # extract speedlimit as number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add weekday and our\n",
    "label_df_new['hour'] = label_df_new.observation_interval_start.dt.hour\n",
    "label_df_new['weekday'] = label_df_new.observation_interval_start.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 500 radius only and rename the column for consistency\n",
    "label_df_500_only = label_df_new.drop([\"commercial_100\", \"residential_100\", \"transportation_100\", \"schools_100\", \"eventsites_100\",\n",
    "                                \"commercial_150\", \"residential_150\", \"transportation_150\", \"schools_150\", \"eventsites_150\", \n",
    "                                \"commercial_250\", \"residential_250\", \"transportation_250\", \"schools_250\", \"eventsites_250\",\n",
    "                                \"commercial_25\", \"residential_25\", \"transportation_25\", \"schools_25\", \"eventsites_25\",\n",
    "                                \"commercial_50\", \"residential_50\", \"transportation_50\", \"schools_50\", \"eventsites_50\"], axis = 1)\n",
    "\n",
    "label_df_500_only = label_df_500_only.rename(\n",
    "    columns={\"commercial_500\": \"commercial\", \n",
    "             \"residential_500\": \"residential\",\n",
    "             \"transportation_500\": \"transportation\",\n",
    "              \"schools_500\": \"schools\",\n",
    "             \"eventsites_500\": \"eventsites\" \n",
    "            }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a764ad7",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4261355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result of different radius\n",
    "csv_buffer = io.StringIO()\n",
    "label_df_new.to_csv(csv_buffer)\n",
    "response = s3_client.put_object( \n",
    "    Bucket=config.get(\"global\").get(\"s3_bucket\"),\n",
    "    Body=csv_buffer.getvalue(),\n",
    "    Key='input/processed/frontend/different_radius_seattle_groundtruth_labels_with_openstreetmap_features.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result for one radius 500\n",
    "csv_buffer = io.StringIO()\n",
    "label_df_500_only.to_csv(csv_buffer)\n",
    "response = s3_client.put_object( \n",
    "    Bucket=config.get(\"global\").get(\"s3_bucket\"),\n",
    "    Body=csv_buffer.getvalue(),\n",
    "    Key='input/processed/frontend/new_seattle_groundtruth_labels_with_openstreetmap_features.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a2f59",
   "metadata": {},
   "source": [
    "## Catboost - might be moved to new notebook later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "!pip install pulearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pulearn import ElkanotoPuClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be350694",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['length', 'highway', 'commercial', 'residential', 'transportation', 'schools', 'eventsites','hour','weekday']\n",
    "cat_features = ['highway', 'hour', 'weekday'] #specify which of the features from above are categorical\n",
    "cat_feat_pos = np.where([feat in cat_features for feat in feature_names])[0] #position of categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df[cat_features] = label_df[cat_features].astype(\"str\")\n",
    "label_df[[feat for feat in feature_names if feat not in cat_features]] = label_df[[feat for feat in feature_names if feat not in cat_features]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: some of the features are lists, we should investigate if that's what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838bdce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(label_df[feature_names], label_df['availability'].astype(\"int\"), test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc8f0a",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elkan_model = CatBoostClassifier(cat_features=cat_feat_pos, metric_period=100)\n",
    "# elkan_model = ElkanotoPuClassifier(base_elkan_model,hold_out_ratio=0.2)\n",
    "base_elkan_model.fit(x_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac2f3d",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, precision_score, accuracy_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=base_elkan_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'recall {recall_score(y_pred=pred,y_true=y_test)}')\n",
    "print(f'precision {precision_score(y_pred=pred,y_true=y_test)}')\n",
    "print(f'accuracy {precision_score(y_pred=pred,y_true=y_test)}')\n",
    "print(f'auc {roc_auc_score(y_score=pred, y_true=y_test)}')\n",
    "print(f'F1-Score: {f1_score(y_true=y_test, y_pred=pred)}')\n",
    "print(f'Mathew Correlation: {matthews_corrcoef(y_true=y_test, y_pred=pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what we can do to tweak the model:\n",
    "# - change the clustering of the POIs\n",
    "# - change the radius (currently 500m) for the POIS\n",
    "# - include more/other OpenStreetMap data\n",
    "# - use another classifier than CatBoost\n",
    "# - hyperparameter tuning\n",
    "# - make the problem a regressionn problem (how many free spaces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
