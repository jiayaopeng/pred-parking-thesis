{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "As of August 16th, 2021, it was found that when we query the heremap data, that some smaller radius has bigger number of POI counts than the bigger radius, especially transportation and office, and we do not know why that is the case, and it was decided to use a helper function later to make the POI count consistent with the radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install pyprobar\n",
    "!pip install catboost\n",
    "!pip install xmltodict\n",
    "!pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import importlib\n",
    "from shapely.wkt import loads\n",
    "import here_maps_helper\n",
    "import evaluation_helper\n",
    "\n",
    "importlib.reload(here_maps_helper)\n",
    "importlib.reload(evaluation_helper)\n",
    "\n",
    "from here_maps_helper import *\n",
    "from evaluation_helper import compare_feature_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load open street map groundtruth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client= boto3.client('s3')\n",
    "csv_obj = client.get_object(Bucket='bucket-vwfs-pred-park-global-model-serving-dev', \n",
    "                            Key=\"input/processed/frontend/different_radius_6_radius_seattle_groundtruth_labels_with_openstreetmap_features.csv\")\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "event_data = pd.read_csv(io.StringIO(csv_string), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include Here geolocation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data.geometry = event_data.geometry.map(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention! Running below two cells produesc approx 5000 API calls against HERE discovery API, where we have monthly limits of 250k request\n",
    "buildings = ['restaurant', 'shopping', 'office', 'supermarket', 'transportation', 'schools']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query API to get data for different radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for diff radius, each call will generate 5000 api call, with a monthly budget of 250, 000\n",
    "data_with_neighbourhood_25 = add_neighbourhood_info_here(event_data, 25, buildings, 'seattle')\n",
    "data_with_neighbourhood_25.to_csv(\"new_seattle_static_map_features_25.csv\")\n",
    "\n",
    "data_with_neighbourhood_50 = add_neighbourhood_info_here(event_data, 50, buildings, 'seattle')\n",
    "data_with_neighbourhood_50.to_csv(\"new_seattle_static_map_features_50.csv\")\n",
    "\n",
    "data_with_neighbourhood_100 = add_neighbourhood_info_here(event_data, 100, buildings, 'seattle')\n",
    "data_with_neighbourhood_100.to_csv(\"new_seattle_static_map_features_100.csv\")\n",
    "\n",
    "data_with_neighbourhood_150 = add_neighbourhood_info_here(event_data, 150, buildings, 'seattle')\n",
    "data_with_neighbourhood_150.to_csv(\"new_seattle_static_map_features_150.csv\")\n",
    "\n",
    "data_with_neighbourhood_250 = add_neighbourhood_info_here(event_data, 250, buildings, 'seattle')\n",
    "data_with_neighbourhood_250.to_csv(\"new_seattle_static_map_features_250.csv\")\n",
    "\n",
    "data_with_neighbourhood_500 = add_neighbourhood_info_here(event_data, 500, buildings, 'seattle')\n",
    "data_with_neighbourhood_500.to_csv(\"new_seattle_static_map_features_500.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files of different radius to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload separate files to s3\n",
    "files = [\"new_seattle_static_map_features_25.csv\", \"new_seattle_static_map_features_50.csv\",\n",
    "         \"new_seattle_static_map_features_100.csv\", \"new_seattle_static_map_features_150.csv\", \n",
    "         \"new_seattle_static_map_features_250.csv\",\"new_seattle_static_map_features_500.csv\"]\n",
    "\n",
    "for file in files:\n",
    "    print(f'uploading {file} to object here_evaluation/seattle/new_different_radius_{file} in s3')\n",
    "    client.upload_file(f'{file}', 'bucket-vwfs-pred-park-global-model-serving-dev', f'Here_evaluation/seattle/different_radius_{file}')\n",
    "    print(f'{file} upload finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv from S3 and add different radius feature together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_neighbourhood_25 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_seattle_static_map_features_25.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_neighbourhood_50 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_seattle_static_map_features_50.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_neighbourhood_100 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_seattle_static_map_features_100.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_neighbourhood_150 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_seattle_static_map_features_150.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_neighbourhood_250 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_seattle_static_map_features_250.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_neighbourhood_500 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_seattle_static_map_features_500.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = event_data.set_index(['street_id', 'observation_interval_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all the radius together and make one dataframe\n",
    "# select the columns, rename the column, and putting it together\n",
    "\n",
    "ls_neighbourhood_df = {\n",
    "    'base': event_data,\n",
    "    '25': data_with_neighbourhood_25,\n",
    "    '50': data_with_neighbourhood_50,\n",
    "    '100': data_with_neighbourhood_100, \n",
    "    '150': data_with_neighbourhood_150, \n",
    "    '250': data_with_neighbourhood_250, \n",
    "    '500': data_with_neighbourhood_500\n",
    "}\n",
    "# save the dataframe with selected columns to new dictionary \n",
    "dict_neighbourhood_df = {}\n",
    "for key, df in ls_neighbourhood_df.items():\n",
    "    if key == 'base':\n",
    "        dict_neighbourhood_df[key] = df\n",
    "    else:\n",
    "        dict_neighbourhood_df[key] = df[buildings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns for each datafame and save to a new dict\n",
    "dict_neighbourhood_df_renamed = {}\n",
    "for key, df in dict_neighbourhood_df.items():\n",
    "    if key == 'base':\n",
    "        dict_neighbourhood_df_renamed[key] = df\n",
    "    \n",
    "    else:\n",
    "        dict_neighbourhood_df_renamed[key] = df.rename(\n",
    "            columns={\n",
    "                'restaurant': f'restaurant_here_{key}',\n",
    "                'shopping': f'shopping_here_{key}',\n",
    "                'office': f'office_here_{key}',\n",
    "                'supermarket': f'supermarket_here_{key}',\n",
    "                'transportation': f'transportation_here_{key}', # need to mark the here due to overlapping name\n",
    "                'schools': f'schools_here_{key}' # need to mark here due to overlapping name\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_new_6_radius_data_with_neighbourhood = pd.concat(dict_neighbourhood_df_renamed.values(), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and upload final file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_new_6_radius_data_with_neighbourhood.to_csv('different_radius_new_6_radius_seattle_static_map_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file('different_radius_new_6_radius_seattle_static_map_features.csv', 'bucket-vwfs-pred-park-global-model-serving-dev', \"Here_evaluation/seattle/different_radius_new_6_radius_seattle_static_map_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare here maps features against open street map features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_neighbourhood = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_new_6_radius_seattle_static_map_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_neighbourhood.geometry = data_with_neighbourhood.geometry.map(loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_feature_names = ['length', 'highway', \n",
    "                    'commercial_25', 'residential_25', 'transportation_25','schools_25', 'eventsites_25',\n",
    "                    'commercial_50', 'residential_50', 'transportation_50','schools_50', 'eventsites_50',\n",
    "                    'commercial_100', 'residential_100', 'transportation_100','schools_100', 'eventsites_100', \n",
    "                    'commercial_150', 'residential_150','transportation_150', 'schools_150', 'eventsites_150', \n",
    "                    'commercial_250','residential_250', 'transportation_250', 'schools_250','eventsites_250', \n",
    "                    'commercial_500', 'residential_500', 'transportation_500', 'schools_500', 'eventsites_500']\n",
    "here_feature_names = ['restaurant_here_25','shopping_here_25', 'office_here_25', 'supermarket_here_25', 'transportation_here_25', 'schools_here_25',\n",
    "                      'restaurant_here_50','shopping_here_50', 'office_here_50', 'supermarket_here_50', 'transportation_here_50', 'schools_here_50', \n",
    "                      'restaurant_here_100','shopping_here_100', 'office_here_100', 'supermarket_here_100', 'transportation_here_100', 'schools_here_100', \n",
    "                      'restaurant_here_150','shopping_here_150', 'office_here_150', 'supermarket_here_150','transportation_here_150', 'schools_here_150', \n",
    "                      'restaurant_here_250', 'shopping_here_250', 'office_here_250', 'supermarket_here_250','transportation_here_250', 'schools_here_250', \n",
    "                      'restaurant_here_500', 'shopping_here_500', 'office_here_500', 'supermarket_here_500','transportation_here_500', 'schools_here_500']\n",
    "time_feat = ['hour','weekday']\n",
    "cat_features = ['highway', 'hour', 'weekday'] \n",
    "feature_dict = {'os_feat': os_feature_names, 'here_feat': here_feature_names, 'here_osm': here_feature_names + os_feature_names, \n",
    "                'map and time_feat': here_feature_names + os_feature_names+ time_feat, 'cat_features': cat_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_neighbourhood[cat_features] = data_with_neighbourhood[cat_features].astype(\"str\")\n",
    "data_with_neighbourhood[[feat for feat in os_feature_names if feat not in cat_features]] = data_with_neighbourhood[[feat for feat in os_feature_names if feat not in cat_features]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature_combinations(data_with_neighbourhood, 50 ,feature_dict, 'availability', val_size=0.05, test_size=0.2, disjunct_locations=False, perform_t_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include static parking information from HERE on-street parking API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_capa = add_static_parking_info_here(data_with_neighbourhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_feature_names = ['highway', 'length', \n",
    "                    'commercial_25', 'residential_25', 'transportation_25','schools_25', 'eventsites_25', \n",
    "                    'commercial_50', 'residential_50', 'transportation_50','schools_50', 'eventsites_50', \n",
    "                    'commercial_100', 'residential_100', 'transportation_100','schools_100', 'eventsites_100', \n",
    "                    'commercial_150', 'residential_150','transportation_150', 'schools_150', 'eventsites_150', \n",
    "                    'commercial_250','residential_250', 'transportation_250', 'schools_250','eventsites_250', \n",
    "                    'commercial_500', 'residential_500', 'transportation_500', 'schools_500', 'eventsites_500',\n",
    "                    'restaurant_here_25','shopping_here_25', 'office_here_25', 'supermarket_here_25', 'transportation_here_25', 'schools_here_25', \n",
    "                    'restaurant_here_50','shopping_here_50', 'office_here_50', 'supermarket_here_50', 'transportation_here_50', 'schools_here_50', \n",
    "                    'restaurant_here_100','shopping_here_100', 'office_here_100', 'supermarket_here_100', 'transportation_here_100', 'schools_here_100', \n",
    "                    'restaurant_here_150','shopping_here_150', 'office_here_150', 'supermarket_here_150','transportation_here_150', 'schools_here_150', \n",
    "                    'restaurant_here_250', 'shopping_here_250', 'office_here_250', 'supermarket_here_250','transportation_here_250', 'schools_here_250', \n",
    "                    'restaurant_here_500', 'shopping_here_500', 'office_here_500', 'supermarket_here_500','transportation_here_500', 'schools_here_500']\n",
    "time_feat = ['hour','weekday']\n",
    "parking_feat = [ 'current_capacity']\n",
    "cat_features = ['highway', 'hour', 'weekday'] \n",
    "feature_dict = {'map_feat': map_feature_names, 'map and parking_feat': parking_feat + map_feature_names, \n",
    "                'map and time_feat': time_feat + map_feature_names, 'map_time_parking_feat' : parking_feat + map_feature_names + time_feat,\n",
    "                'cat_features': cat_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature_combinations(data_with_capa, 50, feature_dict, 'availability', val_size=0.05, test_size=0.2, disjunct_locations=False, perform_t_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include nearby off-street parking facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query API to get data for different radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_offstreet_25 = add_off_street_parking_here(data_with_capa, radius = 25)\n",
    "data_with_offstreet_50 = add_off_street_parking_here(data_with_capa, radius = 50)\n",
    "data_with_offstreet_100 = add_off_street_parking_here(data_with_capa, radius = 100)\n",
    "data_with_offstreet_150 = add_off_street_parking_here(data_with_capa, radius = 150)\n",
    "data_with_offstreet_250 = add_off_street_parking_here(data_with_capa, radius = 250)\n",
    "data_with_offstreet_500 = add_off_street_parking_here(data_with_capa, radius = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_offstreet_25.to_csv('data_with_offstreet_25.csv')\n",
    "data_with_offstreet_50.to_csv('data_with_offstreet_50.csv')\n",
    "data_with_offstreet_100.to_csv('data_with_offstreet_100.csv')\n",
    "data_with_offstreet_150.to_csv('data_with_offstreet_150.csv')\n",
    "data_with_offstreet_250.to_csv('data_with_offstreet_250.csv')\n",
    "data_with_offstreet_500.to_csv('data_with_offstreet_500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload separate files to s3\n",
    "files = [\"data_with_offstreet_25.csv\", \"data_with_offstreet_50.csv\",\n",
    "         \"data_with_offstreet_100.csv\", \"data_with_offstreet_150.csv\", \n",
    "         \"data_with_offstreet_250.csv\",\"data_with_offstreet_500.csv\" ]\n",
    "\n",
    "for file in files:\n",
    "    print(f'uploading {file} to object here_evaluation/seattle/different_radius_{file} in s3')\n",
    "    client.upload_file(f'{file}', 'bucket-vwfs-pred-park-global-model-serving-dev', f'Here_evaluation/seattle/different_radius_{file}')\n",
    "    print(f'{file} upload finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv from S3 and add different radius feature together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from s3\n",
    "data_with_offstreet_25 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet_25.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_offstreet_50 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet_50.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_offstreet_100 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet_100.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_offstreet_150 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet_150.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_offstreet_250 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet_250.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])\n",
    "data_with_offstreet_500 = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet_500.csv', index_col=0).set_index(['street_id', 'observation_interval_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_offstreet_cols = ['num_off_street_parking', 'off_street_capa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_capa = data_with_capa.set_index(['street_id', 'observation_interval_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_with_offstreet_df = {\n",
    "    'base': data_with_capa,\n",
    "    '25': data_with_offstreet_25,\n",
    "    '50': data_with_offstreet_50,\n",
    "    '100': data_with_offstreet_100, \n",
    "    '150': data_with_offstreet_150, \n",
    "    '250': data_with_offstreet_250, \n",
    "    '500': data_with_offstreet_500\n",
    "}\n",
    "# save the dataframe with selected columns to new dictionary \n",
    "dict_with_offstreet_df = {}\n",
    "for key, df in ls_with_offstreet_df.items():\n",
    "    if key == 'base':\n",
    "        dict_with_offstreet_df[key] = df\n",
    "    else:\n",
    "        dict_with_offstreet_df[key] = df[with_offstreet_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns for each datafame and save to a new dict\n",
    "dict_with_offstreet_df_renamed = {}\n",
    "for key, df in dict_with_offstreet_df.items():\n",
    "    if key == 'base':\n",
    "        dict_with_offstreet_df_renamed[key] = df\n",
    "    \n",
    "    else:\n",
    "        dict_with_offstreet_df_renamed[key] = df.rename(\n",
    "            columns={\n",
    "                'num_off_street_parking': f'num_off_street_parking_{key}',\n",
    "                'off_street_capa': f'off_street_capa_{key}',\n",
    "    \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_data_with_offstreet = pd.concat(dict_with_offstreet_df_renamed.values(), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and upload final file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_data_with_offstreet.to_csv('different_radius_data_with_offstreet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file('different_radius_data_with_offstreet.csv', 'bucket-vwfs-pred-park-global-model-serving-dev', \"Here_evaluation/seattle/different_radius_data_with_offstreet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_data_with_offstreet = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_data_with_offstreet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_street_parking_feat = [ 'num_off_street_parking_25', 'off_street_capa_25',\n",
    "                            'num_off_street_parking_50', 'off_street_capa_50',\n",
    "                            'num_off_street_parking_100', 'off_street_capa_100',\n",
    "                            'num_off_street_parking_150', 'off_street_capa_150',\n",
    "                            'num_off_street_parking_250', 'off_street_capa_250',\n",
    "                            'num_off_street_parking_500', 'off_street_capa_500']\n",
    "feature_dict = {'map_time_feat': map_feature_names + time_feat, 'map_time_on_street': map_feature_names + time_feat+ parking_feat,\n",
    "                'map_time_off_street':  map_feature_names + time_feat+ off_street_parking_feat, \n",
    "                'map_time_parking': map_feature_names + time_feat+ off_street_parking_feat+parking_feat,\n",
    "                'cat_features': cat_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature_combinations(different_radius_data_with_offstreet, 50 ,feature_dict, 'availability', val_size=0.05, test_size=0.2, disjunct_locations=False, perform_t_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_radius_data_with_offstreet.geometry = different_radius_data_with_offstreet.geometry.map(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_weather = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/input/historic_weather_data/seattle/seattle_weather_groundtruth_dates_2019.csv', index_col=0, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a common daily key to join weather_data with feature df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_weather['time_key'] = seattle_weather.apply(lambda x: x['date'] +'-'+ x['time'][:-2].rjust(2, \"0\"), axis=1 )\n",
    "different_radius_data_with_offstreet['time_key'] = pd.to_datetime(different_radius_data_with_offstreet.observation_interval_start).map(lambda x: x.strftime('%Y-%m-%d-%H'))\n",
    "different_radius_data_with_offstreet['street_id'] = different_radius_data_with_offstreet['street_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = ['tempC', 'windspeedKmph', 'precipMM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match by the time key and get the columns needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_weather = different_radius_data_with_offstreet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_features:\n",
    "    data_with_weather[col] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_with_weather.iterrows():\n",
    "    weather_on_day = seattle_weather[seattle_weather['time_key'] == row['time_key']].iloc[0, :][weather_features]\n",
    "    for feature_name in weather_features:\n",
    "        data_with_weather.at[index, feature_name] = weather_on_day[feature_name]\n",
    "data_with_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {'map_time_feat': map_feature_names + time_feat,\n",
    "                'map_time_parking': map_feature_names + time_feat+ parking_feat,\n",
    "                'map_time_parking_weather': map_feature_names + time_feat + parking_feat + weather_features,\n",
    "                'cat_features': cat_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature_combinations(data_with_weather, 10 ,feature_dict, 'availability', val_size=0.05, test_size=0.2, disjunct_locations=False, perform_t_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_weather.to_csv('different_radius_6_radius_seattle_train_data_here.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file('different_radius_6_radius_seattle_train_data_here.csv', 'bucket-vwfs-pred-park-global-model-serving-dev', \"Here_evaluation/seattle/different_radius_6_radius_seattle_train_data_here.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include calendar effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar_helper import add_extra_time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_weather = pd.read_csv('s3://bucket-vwfs-pred-park-global-model-serving-dev/Here_evaluation/seattle/different_radius_6_radius_seattle_train_data_here.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_weather.observation_interval_start = pd.to_datetime(data_with_weather.observation_interval_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_holiday = add_extra_time_features(data_with_weather, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_holiday.to_csv('different_radius_6_radius_data_with_holiday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file('different_radius_6_radius_data_with_holiday.csv', 'bucket-vwfs-pred-park-global-model-serving-dev', 'input/open_data/seattle/different_radius_6_radius_data_with_holiday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_holiday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_time_feat = ['month', 'day_of_month', 'time_since_last_holiday', 'time_to_next_holiday', 'time_to_next_two_day_holiday', 'time_since_last_two_day_holiday']\n",
    "weather_feat = ['tempC', 'windspeedKmph', 'precipMM']\n",
    "feature_dict = {'no_time_feat': map_feature_names + parking_feat + weather_feat,\n",
    "                'simple_time_feat': map_feature_names + parking_feat + weather_feat +time_feat,\n",
    "                'all_time_feat': map_feature_names + time_feat + parking_feat + weather_feat + advanced_time_feat,\n",
    "                'cat_features': cat_features+ ['month']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature_combinations(data_with_holiday, 50 ,feature_dict, 'availability', val_size=0.05, test_size=0.2, disjunct_locations=False, perform_t_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
