{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684de645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jsonmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import importlib \n",
    "from jsonmerge import merge # merge all the json's together\n",
    "import pprint\n",
    "\n",
    "import results.preprocess as rp\n",
    "import results.analyze as ra\n",
    "import results.visualize as rv\n",
    "\n",
    "importlib.reload(rp) \n",
    "importlib.reload(ra) \n",
    "importlib.reload(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9dd758",
   "metadata": {},
   "source": [
    "We have below hyperparameter tuning settings:\n",
    "\n",
    "**For Coral(Baseline)**\n",
    "\n",
    "     250 tuning jobs and 1 experiments\n",
    "     100 tuning jobs and 3 experiments\n",
    "    \n",
    "    \n",
    "**For DFA**\n",
    "    \n",
    "    Weight tying:\n",
    "    \n",
    "        250 tuning jobs and 1 experiments\n",
    "        100 tuning jobs and 3 experiments\n",
    " \n",
    "    Without weight tying:\n",
    "\n",
    "        250 tuning jobs and 1 experiments \n",
    "        100 tuning jobs and 3 experiments \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "For all the above settings, we are getting the result of the final run. The final run is a process where we used the best hyperparameter combinations selected by the hyperparameter tuning and train a model. For the final run, we used 200 epoch with early stopping, and do 20 experiments.\n",
    "\n",
    "When we have 3 experiments, the matthew will be averaged over all the 3 experiments(details please see the experiment part of the thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "        \"{'Source': ['South Lake Union', 'Commercial Core', 'Pike-Pine', 'Uptown', 'Ballard', 'First Hill', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['Greenlake']}\": 'Greenlake',\n",
    "        \"{'Source': ['Greenlake', 'Commercial Core', 'Pike-Pine', 'Uptown', 'Ballard', 'First Hill', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['South Lake Union']}\": 'South Lake Union',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Pike-Pine', 'Uptown', 'Ballard', 'First Hill', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['Commercial Core']}\": 'Commercial Core',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Commercial Core', 'Uptown', 'Ballard', 'First Hill', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['Pike-Pine']}\": 'Pike-Pine',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Commercial Core', 'Pike-Pine', 'Ballard', 'First Hill', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['Uptown']}\": 'Uptown',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Commercial Core', 'Pike-Pine', 'Uptown', 'First Hill', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['Ballard']}\": 'Ballard',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Commercial Core', 'Pike-Pine', 'Uptown', 'Ballard', 'Chinatown/ID', 'Pioneer Square'], 'Target': ['First Hill']}\": 'First Hill',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Commercial Core', 'Pike-Pine', 'Uptown', 'Ballard', 'First Hill', 'Pioneer Square'], 'Target': ['Chinatown/ID']}\": 'Chinatown/ID',\n",
    "        \"{'Source': ['Greenlake', 'South Lake Union', 'Commercial Core', 'Pike-Pine', 'Uptown', 'Ballard', 'First Hill', 'Chinatown/ID'], 'Target': ['Pioneer Square']}\": 'Pioneer Square'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff434f1",
   "metadata": {},
   "source": [
    "# Get jsons from final run of different settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626b914",
   "metadata": {},
   "source": [
    "    1. Get the whole json file for all the 6 settings specified above. \n",
    "    2. The json file includes the metric like AUC, F1 and so on, later we will only use matthew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc38297",
   "metadata": {},
   "source": [
    "### Coral "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08968a5a",
   "metadata": {},
   "source": [
    "#### Coral final run(tuned 250 hyperparameter jobs with 1 experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Parking-Coral-jobs_tune250_exp1.json', 'r') as f:\n",
    "    name_dict_coral_tune250_exp1 = json.load(f)\n",
    "    \n",
    "# retrive the result from that job\n",
    "coral_tune250_exp1 = rp.get_results(name_dict_coral_tune250_exp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51084102",
   "metadata": {},
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! Just run json.load to read the json file, instead of json.dump\n",
    "with open(f'Parking-Coral-results_tune250_exp1.json', 'w') as f:\n",
    "     json.dump(coral_tune250_exp1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36ebe6",
   "metadata": {},
   "source": [
    "#### Coral final run(tuned 100 hyperparameter jobs with 3 experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e84ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Parking-Coral-jobs_tune100_exp3.json', 'r') as f:\n",
    "    name_dict_coral_tune100_exp3 = json.load(f)\n",
    "    \n",
    "# retrive the result from that job\n",
    "coral_tune100_exp3 = rp.get_results(name_dict_coral_tune100_exp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ad049",
   "metadata": {},
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! Just run json.load to read the json file, instead of json.dump\n",
    "with open(f'Parking-Coral-results_tune100_exp3.json', 'w') as f:\n",
    "     json.dump(coral_tune100_exp3,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3f3a3",
   "metadata": {},
   "source": [
    "### DFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e6cb4",
   "metadata": {},
   "source": [
    "#### DFA final run(tuned 250 hyperparameter jobs with 1 experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Parking-DFA-jobs_tune250_exp1.json', 'r') as f:\n",
    "    name_dict_dfa_tune250_exp1 = json.load(f)\n",
    "    \n",
    "# retrive the result from that job\n",
    "dfa_tune250_exp1 = rp.get_results(name_dict_dfa_tune250_exp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4a37d",
   "metadata": {},
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! Just run json.load to read the json file, instead of json.dump\n",
    "with open(f'Parking-DFA-results_tune250_exp1.json', 'w') as f:\n",
    "     json.dump(dfa_tune250_exp1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1861931",
   "metadata": {},
   "source": [
    "#### DFA final run(tuned 100 hyperparameter jobs with 3 experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Parking-DFA-jobs_tune100_exp3.json', 'r') as f:\n",
    "    name_dict_dfa_tune100_exp3 = json.load(f)\n",
    "    \n",
    "# retrive the result from that job\n",
    "dfa_tune100_exp3 = rp.get_results(name_dict_dfa_tune100_exp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e38a3",
   "metadata": {},
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! Just run json.load to read the json file, instead of json.dump\n",
    "with open(f'Parking-DFA-results_tune100_exp3.json', 'w') as f:\n",
    "     json.dump(dfa_tune100_exp3,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3374d02",
   "metadata": {},
   "source": [
    "#### DFA final run with weight tying(tuned 250 hyperparameter jobs with 1 experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581699fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Parking-DFA-jobs_wt_tune250_exp1.json', 'r') as f:\n",
    "    name_dict_dfa_wt_tune250_exp1 = json.load(f)\n",
    "    \n",
    "# retrive the result from that job\n",
    "dfa_wt_tune250_exp1 = rp.get_results(name_dict_dfa_wt_tune250_exp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffe486",
   "metadata": {},
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! Just run json.load to read the json file, instead of json.dump!!\n",
    "with open(f'Parking-DFA-results_wt_tune250_exp1.json', 'w') as f:\n",
    "     json.dump(dfa_wt_tune250_exp1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ceb5d2",
   "metadata": {},
   "source": [
    "#### DFA final run with weight tying(tuned 100 hyperparameter jobs with 3 experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbbf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Parking-DFA-jobs_wt_tune100_exp3.json', 'r') as f:\n",
    "    name_dict_dfa_wt_tune100_exp3 = json.load(f)\n",
    "    \n",
    "# retrive the result from that job\n",
    "dfa_wt_tune100_exp3 = rp.get_results(name_dict_dfa_wt_tune100_exp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b327a3ec",
   "metadata": {},
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! Just run json.load to read the json file, instead of json.dump\n",
    "with open(f'Parking-DFA-results_wt_tune100_exp3.json', 'w') as f:\n",
    "     json.dump(dfa_wt_tune100_exp3,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1acd1",
   "metadata": {},
   "source": [
    "#### Put all the jsons in one big json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** DO NOT THIS CELL RUN IF YOU JUST NEED TO VIEW JSON FILE! RUN below cell with json.read instead!!\n",
    "result_coral = merge(coral_tune250_exp1, coral_tune100_exp3)\n",
    "result_dfa = merge(dfa_tune250_exp1, dfa_tune100_exp3)\n",
    "result_dfa_weight_tying = merge(dfa_wt_tune250_exp1, dfa_wt_tune100_exp3)\n",
    "\n",
    "\n",
    "result_temp = merge(result_coral, result_dfa)\n",
    "result = merge(result_temp, result_dfa_weight_tying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_coral.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dfa.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dfa_weight_tying.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516ced4",
   "metadata": {},
   "source": [
    "with open('result_all.json', 'w') as f:\n",
    "    json.dump(result ,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_all.json', 'r') as f:\n",
    "    result = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8fd81",
   "metadata": {},
   "source": [
    "# Preprocess the Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece0452",
   "metadata": {},
   "source": [
    "    1. swap the key between metric and area(area first and then metric)\n",
    "    2. rename the area with only the target area and rename the matthew to test_matthew to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27148419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this map matches the final run job name with the hyperparameter experiment setting name (no. of jobs and exepriments)\n",
    "setting_map = {\n",
    "    'domain-adaptation_Coral-final-domain-adaptation-Tune250Ex-2021-09-12-08-38-45-347_output': 'Coral-tune-250-job-1-experi',\n",
    "    'domain-adaptation_Coral-final-domain-adaptation-Tune100Ex-2021-09-12-17-19-31-644_output': 'Coral-tune-100-job-3-experi',\n",
    "    'domain-adaptation_DFA-final-domain-adaptation-2021-09-08-19-37-27-999_output':'DFA-tune-250-job-1-experi',\n",
    "    'domain-adaptation_DFA-final-domain-adaptation-2021-09-09-20-39-14-131_output': 'DFA-tune-100-job-3-experi',\n",
    "    'domain-adaptation_DFA-final-domain-adaptation-2021-09-09-15-39-08-635_output': 'DFA-weight-tie-tune-250-job-1-experi',\n",
    "    'domain-adaptation_DFA-final-domain-adaptation-2021-09-11-11-23-18-211_output': 'DFA-weight-tie-tune-100-job-3-experi'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the first level key according to above map, so we could better distiguish between different settings\n",
    "\n",
    "for old_name, new_name in setting_map.items():\n",
    "    if old_name in list(result.keys()):\n",
    "        result[new_name] = result.pop(old_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a53848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean\n",
    "df_means_raw = rp.get_metric_df(result, get_mean=True)\n",
    "# rename and only select matthews\n",
    "df_means = rp.select_matthew_rename(df_means_raw, name_map)\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_raw = rp.get_metric_df(result, get_mean=False)\n",
    "df_all = rp.select_matthew_rename(df_all_raw, name_map)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28048d27",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3c5c88",
   "metadata": {},
   "source": [
    "## Get Mean of Matthew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897bd7d",
   "metadata": {},
   "source": [
    "For each algorithm, for each experiments setting, get their average matthew result. The average is calculated by averaging across different area combinations and different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77545aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mean = ra.get_mean_of_mean(df_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72956c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting 100 -300 jobs, reduced a little (brifef)\n",
    "# 250 abosumute number may not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv.plot_mean_of_mean(mean_of_mean, figsize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5427fd",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e41541",
   "metadata": {},
   "source": [
    "## Correlation between no. of data points in area and the matthew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6efce1",
   "metadata": {},
   "source": [
    "For the setting which gives us the highest validation matthew, we plot the correlation between the number of data points in one area and the test_matthew or val matthew "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c43469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name of setting which gives highest test matthew and get the dataframe\n",
    "highest_val_mean = mean_of_mean.loc[mean_of_mean['avg_test_matthew'] == mean_of_mean['avg_test_matthew'].max()].index[0]\n",
    "df_highest_mean = df_means.loc[(slice(None), highest_val_mean),:]\n",
    "\n",
    "# drop the setting level index\n",
    "df_highest_mean.index =  df_highest_mean.index.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_val_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ab622",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.corr_area_size_matthew(df_highest_mean, highest_val_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4337f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coral easy(clustering), domain shift tackle, does not need too many data points, output model DFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f679d",
   "metadata": {},
   "source": [
    "## Boxplot for valid and test matthew across areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a764015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get that setting's df\n",
    "df = df_all.loc[(slice(None), highest_val_mean),:]\n",
    "df.index = df.loc[(slice(None), highest_val_mean),:].index.droplevel(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569272b6",
   "metadata": {},
   "source": [
    "#### only plot test matthew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef630c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess --to be able to plot the box plot\n",
    "data_test_matthew = rp.preprocess_for_boxplot(df,test_matthew_only=True)\n",
    "\n",
    "# plot box \n",
    "rv.plot_matthew_per_area(data_test_matthew , highest_val_mean, (15,9)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65af774",
   "metadata": {},
   "source": [
    "#### plot both test and valid matthew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess --to be able to plot the box plot\n",
    "data = rp.preprocess_for_boxplot(df)\n",
    "\n",
    "# plot box \n",
    "rv.plot_matthew_per_area(data, highest_val_mean, (15,9)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7b23e",
   "metadata": {},
   "source": [
    "**The results we have outperform the baseline model(Catboost model direct transfer on hold out area with matthew score 0.160) by very small amount. As we can see, there is overfitting from in validation set for all the areas, even we did a random split to generate the validation and test dataset. There are several ways we think could be elivating this kind of overfitting:**\n",
    "    \n",
    "    1) As we have started 250 jobs when we tune the hyperparameter, we could reduce the number of searching hyperparameter jobs to 100.\n",
    "    2) Our search has used early stop within the epochs, so we do not need to change here\n",
    "    3) we could increase the number of experiments, as for this case, we only run 1 experiments, it might be that the hyperparameter we get on that one experiments is by coincidance, therefore we could run 3 experiments and use the averaged result of those;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}