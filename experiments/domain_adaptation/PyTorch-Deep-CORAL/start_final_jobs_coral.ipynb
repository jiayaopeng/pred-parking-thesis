{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af754afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import json\n",
    "import time \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0786236",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"Coral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"Parking\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375bb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_name = \"Tune100Exp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c44127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data must come from S3 (in the same region as the notebook instance is)\n",
    "\n",
    "region = sagemaker_session.boto_region_name \n",
    "\n",
    "# datainput\n",
    "if region == \"eu-west-1\":\n",
    "    seattle = 's3://vwfs-pred-park-irland/input/open_data/seattle/train_data_with_trans_100_with_transaction.csv'\n",
    "    bucket_name = 'vwfs-pred-park-irland'\n",
    "    \n",
    "elif region == \"eu-central-1\":\n",
    "    seattle = 's3://bucket-vwfs-pred-park-global-model-serving-dev/input/open_data/seattle/train_data_with_trans_100_with_transaction.csv'\n",
    "    bucket_name = 'bucket-vwfs-pred-park-global-model-serving-dev'\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(\"Region must be eu-west-1 or eu-central-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not region == \"eu-west-1\":\n",
    "    raise NotImplementedError(\"Hyperparameter tuning was performed in eu-west-1.\")\n",
    "\n",
    "#if not algorithm == \"DFA\":\n",
    "#    raise NotImplementedError(\"Algorithm must be DFA\")\n",
    "    \n",
    "if task_name == \"Parking\":\n",
    "    # add the jobs\n",
    "    tuner_job_list = [\"Parking-coral-with-a-210912-1012\"]\n",
    "    training_input = {'seattle': seattle} # csv files from the seattle\n",
    "    job_specific_params = [\"source_only\"] # this will take the params from the current tuning job\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(\"Task must be Parking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab67fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resources = {'ml.g4dn.xlarge' : 10,\n",
    "               'ml.g4dn.2xlarge': 10} # needed for function to check which resources are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46520344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of param in hyperparams, n experience >1\n",
    "tune_params = [\"lr\", \"batch_size\" , \"optimizer\",\"include_pbp\", \"use_batchnorm\", \"hidden_dim\", \"output_dim\", \"lambda_coral\"]\n",
    "#tune_params = [\"lr\", \"batch-size\" , \"optimizer\", \"use_batchnorm\", \"hidden_dim\",'lambda_1','lambda_2', \"output_dim\"]\n",
    "fixed_params = {\n",
    "                \"sm_mode\": 1,\n",
    "                \"n_experiments\": 20, # no. of experiments, eg. tuner jobs -> call main file -> no. experiments -> no. of epoch\n",
    "                \"max_epoch\": 200,\n",
    "                \"patience\": 10,\n",
    "                \"early_stop\": 1\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as other notebook\n",
    "entry_script = \"train.py\"\n",
    "source_dir = '/home/ec2-user/SageMaker/mobility-predpark-global-ML/research/PyTorch-Deep-CORAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_single_training_job(instance, params, entry_script, job_name, output_path, training_input, source_dir):\n",
    "    estimator= PyTorch(entry_point=entry_script,\n",
    "                role=role,\n",
    "                source_dir=source_dir,\n",
    "                framework_version=\"1.4.0\",\n",
    "                py_version=\"py3\",\n",
    "                instance_count=1,\n",
    "                instance_type=instance,\n",
    "                hyperparameters=params,\n",
    "                base_job_name=job_name,\n",
    "                output_path = output_path)\n",
    "    \n",
    "    estimator.fit(training_input, wait=False)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_available_resource(s3_resources):\n",
    "    avail_resource = [resource for resource, avail_num in s3_resources.items() if avail_num > 0]\n",
    "    if len (avail_resource)==0:\n",
    "        return -1\n",
    "    select_resource = avail_resource[0]\n",
    "    s3_resources[select_resource] = s3_resources[select_resource] -1\n",
    "    return select_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57043701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_job_parameters(tuner_job, tune_params, job_specific_params, fixed_params):\n",
    "    tuner = sagemaker.tuner.HyperparameterTuner.attach(tuner_job)\n",
    "    # retrieve job specific from tuner\n",
    "    job_specific_params = pd.DataFrame([tuner.describe()['TrainingJobDefinition']['StaticHyperParameters']])[job_specific_params].iloc[0].to_dict()\n",
    "    print('job_specific_params', job_specific_params)\n",
    "    job_specific_params['source_only'] = int(job_specific_params['source_only'])\n",
    "    fixed_params = {**fixed_params, **job_specific_params}\n",
    "\n",
    "    #from tuner.analystics, retrieve get best params\n",
    "    res = tuner.analytics().dataframe()\n",
    "    for col in res.columns:\n",
    "        res[col] = res[col].map(lambda x: x.replace('\"','') if type(x)==str else x)\n",
    "    print(res.columns)\n",
    "    print(tune_params)\n",
    "    best_params = res.iloc[res.FinalObjectiveValue.argmax()][tune_params].to_dict()\n",
    "    best_params['batch_size'] = int(best_params['batch_size'])\n",
    "    best_params['use_batchnorm'] = int(best_params['use_batchnorm'])\n",
    "    #best_params['include_pbp'] = int(best_params['include_pbp'])\n",
    "    best_params['hidden_dim'] = int(best_params['hidden_dim'])\n",
    "    best_params['output_dim'] = int(best_params['output_dim'])\n",
    "    final_params = {**best_params, **fixed_params}\n",
    "    #sagemaker saves the cate to str, now we need to remove it\n",
    "    for key in final_params:\n",
    "        final_params[key] = final_params[key].replace('\"', '') if type(final_params[key]) == str else final_params[key]\n",
    "    print(final_params)\n",
    "    \n",
    "    return final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_names(algorithm, source_only, bucket):\n",
    "    if source_only: # if string was always\n",
    "        task_name = f\"source-only\"\n",
    "    else:\n",
    "        task_name = f\"domain-adaptation\" # names needs to be- not _\n",
    "        \n",
    "    output_path = f\"s3://{bucket}/research/{algorithm}/saved_model/{task_name}\"\n",
    "    training_job_name = f\"{algorithm}-final-{task_name}-{setting_name}\".replace(' ', '-')\n",
    "    \n",
    "    return output_path, training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_resource(estimator_list):\n",
    "    resource = -1\n",
    "    max_wait_time = 600 \n",
    "    for i in range(max_wait_time):\n",
    "        for estimator in estimator_list:\n",
    "            if estimator.latest_training_job.describe()['TrainingJobStatus'] == 'Completed':\n",
    "                resource = estimator.latest_training_job.describe()['ResourceConfig']['InstanceType']\n",
    "                estimator_list.remove(estimator)\n",
    "                return resource\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6914db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training jobs, result of whole loop will be a json file\n",
    "estimator_list = []\n",
    "name_dict = {'estimators': []}\n",
    "for tuner_job in tuner_job_list:\n",
    "    #for iterator in iterator_list:\n",
    "    #    print(f\"starting new job: {iterator}\")\n",
    "    params = get_training_job_parameters(tuner_job, tune_params, job_specific_params, fixed_params)\n",
    "    print(params)\n",
    "    resource = select_available_resource(s3_resources)\n",
    "    if resource == -1:\n",
    "        resource = wait_for_resource(estimator_list)\n",
    "    # create names\n",
    "    output_path, training_job_name = create_names(algorithm, params['source_only'],bucket_name)\n",
    "    print('output_path')\n",
    "    print(output_path)\n",
    "    print('training_job_name')\n",
    "    print(training_job_name)\n",
    "    estimator = start_single_training_job(resource, params, entry_script, training_job_name, output_path, training_input, source_dir)\n",
    "    estimator_list.append(estimator)\n",
    "    output_path_name = estimator.output_path\n",
    "    estimator_job_name = estimator.latest_training_job.describe()['TrainingJobName']\n",
    "    estimator_path = '/'.join([output_path_name, estimator_job_name])\n",
    "    name_dict['estimators']= name_dict['estimators'] + [estimator_path]\n",
    "    with open(f'{task_name}-{algorithm}-jobs.json', 'w') as f:\n",
    "        json.dump(name_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3152301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
