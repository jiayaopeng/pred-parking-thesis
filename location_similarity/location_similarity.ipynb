{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Imports"
   ],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install category_encoders\n",
    "!pip install geopandas\n",
    "!pip install folium\n",
    "!pip install geopy\n",
    "!pip install catboost"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from category_encoders) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from category_encoders) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from category_encoders) (0.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
      "Requirement already satisfied: six in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: geopandas in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: shapely>=1.6 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.7.1)\n",
      "Requirement already satisfied: fiona>=1.8 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.8.20)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (3.2.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.1.3)\n",
      "Requirement already satisfied: attrs>=17 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: munch in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six>=1.7 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
      "Requirement already satisfied: click>=4.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: certifi in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (2020.6.20)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->geopandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->geopandas) (1.19.2)\n",
      "Requirement already satisfied: folium in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from folium) (2.11.2)\n",
      "Requirement already satisfied: requests in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from folium) (2.24.0)\n",
      "Requirement already satisfied: numpy in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from folium) (1.19.2)\n",
      "Requirement already satisfied: branca>=0.3.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from folium) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=2.9->folium) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from requests->folium) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from requests->folium) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from requests->folium) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from requests->folium) (2.10)\n",
      "Requirement already satisfied: geopy in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from geopy) (1.52)\n",
      "Requirement already satisfied: catboost in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (0.26.1)\n",
      "Requirement already satisfied: scipy in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: matplotlib in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: plotly in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (5.3.1)\n",
      "Requirement already satisfied: six in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: graphviz in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (0.17)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/prisc/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2020.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 1.1. Local imports\n",
    "# # this is only used when running in sagemer mode\n",
    "import location_similarity_helper as lsh\n",
    "import location_similarity_plots as lsp\n",
    "import location_similarity_cluster as lsc\n",
    "import location_similarity_train_evaluate as lste\n",
    "from baseline_helper import create_area_combinations\n",
    "\n",
    "\n",
    "# 1.2. External imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import geopy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely import wkt\n",
    "from sklearn import preprocessing\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "importlib.reload(lsp)\n",
    "importlib.reload(lsh)\n",
    "importlib.reload(lsc)\n",
    "importlib.reload(lste)\n",
    "\n",
    "pd.set_option('display.max_column', 500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.Load Input Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sagemaker_mode = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "if sagemaker_mode:\n",
    "    # get the import\n",
    "    from setup import load_data_from_s3 \n",
    "    # read data\n",
    "    bucket_name = 'bucket-vwfs-pred-park-global-model-serving-dev'\n",
    "    file_name = 'input/open_data/seattle/train_data_with_trans_100_with_transaction.csv'\n",
    "    train_data_with_trans_100 = load_data_from_s3(bucket_name, file_name)\n",
    "\n",
    "else: # if run locally\n",
    "    print(f'current working directory: {os.getcwd()}')  # Get the current working directory (cwd)\n",
    "    cwd = os.chdir(\"/Users/prisc/Code/pred-parking-thesis/\")# change the directory\n",
    "    files = os.listdir(cwd)  # Get all the files in that directory\n",
    "    print(\"Files in %r: %s\" % (cwd, files))\n",
    "    # read the data\n",
    "    train_data_with_trans_100 = pd.read_csv('data/train_data_with_trans_100_with_transaction.csv', index_col=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current working directory: /Users/prisc/Code/pred-parking-thesis/location_similarity\n",
      "Files in None: ['DFA', 'preprocess', 'README.md', 'location_similarity', '.git', 'data', 'PyTorch-Deep-CORAL']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_data_with_trans_100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street_id</th>\n",
       "      <th>observation_interval_start</th>\n",
       "      <th>availability</th>\n",
       "      <th>length</th>\n",
       "      <th>highway</th>\n",
       "      <th>maxspeed</th>\n",
       "      <th>geometry</th>\n",
       "      <th>study_area</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>commercial_100</th>\n",
       "      <th>residential_100</th>\n",
       "      <th>transportation_100</th>\n",
       "      <th>schools_100</th>\n",
       "      <th>eventsites_100</th>\n",
       "      <th>restaurant_here_100</th>\n",
       "      <th>shopping_here_100</th>\n",
       "      <th>office_here_100</th>\n",
       "      <th>supermarket_here_100</th>\n",
       "      <th>transportation_here_100</th>\n",
       "      <th>schools_here_100</th>\n",
       "      <th>capacity</th>\n",
       "      <th>hourly_capacity</th>\n",
       "      <th>current_capacity</th>\n",
       "      <th>num_off_street_parking_100</th>\n",
       "      <th>off_street_capa_100</th>\n",
       "      <th>time_key</th>\n",
       "      <th>tempC</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>ongoing_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1262</td>\n",
       "      <td>2019-03-21 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.470</td>\n",
       "      <td>residential</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.30894 47.6061773, -122.308940...</td>\n",
       "      <td>Cherry Hill</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2019-03-21-08</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18459</td>\n",
       "      <td>2019-03-21 08:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.091</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.30894 47.6061773, -122.309064...</td>\n",
       "      <td>Cherry Hill</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2019-03-21-08</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1257</td>\n",
       "      <td>2019-03-21 08:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.755</td>\n",
       "      <td>secondary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3102402 47.6080375, -122.3103...</td>\n",
       "      <td>Cherry Hill</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-03-21-08</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>2019-03-21 08:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.589</td>\n",
       "      <td>secondary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3089518 47.6080341, -122.3096...</td>\n",
       "      <td>Cherry Hill</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-21-08</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1262</td>\n",
       "      <td>2019-03-21 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.470</td>\n",
       "      <td>residential</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.30894 47.6061773, -122.308940...</td>\n",
       "      <td>Cherry Hill</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2019-03-21-09</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>18065</td>\n",
       "      <td>2019-06-05 19:12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.269</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (-122.316779 47.6074153, -122.31677...</td>\n",
       "      <td>12th Ave</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-05-19</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>18065</td>\n",
       "      <td>2019-06-05 20:10:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.269</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (-122.316779 47.6074153, -122.31677...</td>\n",
       "      <td>12th Ave</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-05-20</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>18065</td>\n",
       "      <td>2019-06-05 21:15:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.269</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (-122.316779 47.6074153, -122.31677...</td>\n",
       "      <td>12th Ave</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-05-21</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>18065</td>\n",
       "      <td>2019-06-05 22:12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.269</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (-122.316779 47.6074153, -122.31677...</td>\n",
       "      <td>12th Ave</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-05-22</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>18065</td>\n",
       "      <td>2019-06-05 23:07:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.269</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (-122.316779 47.6074153, -122.31677...</td>\n",
       "      <td>12th Ave</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-05-23</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5857 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      street_id observation_interval_start  availability   length  \\\n",
       "0          1262        2019-03-21 08:00:00           0.0  206.470   \n",
       "1         18459        2019-03-21 08:00:00           1.0   99.091   \n",
       "2          1257        2019-03-21 08:00:00           1.0   98.755   \n",
       "3          1259        2019-03-21 08:00:00           1.0   96.589   \n",
       "4          1262        2019-03-21 09:00:00           0.0  206.470   \n",
       "...         ...                        ...           ...      ...   \n",
       "5852      18065        2019-06-05 19:12:00           1.0  134.269   \n",
       "5853      18065        2019-06-05 20:10:00           1.0  134.269   \n",
       "5854      18065        2019-06-05 21:15:00           1.0  134.269   \n",
       "5855      18065        2019-06-05 22:12:00           1.0  134.269   \n",
       "5856      18065        2019-06-05 23:07:00           1.0  134.269   \n",
       "\n",
       "          highway  maxspeed  \\\n",
       "0     residential      25.0   \n",
       "1        tertiary      25.0   \n",
       "2       secondary      25.0   \n",
       "3       secondary      25.0   \n",
       "4     residential      25.0   \n",
       "...           ...       ...   \n",
       "5852     tertiary      30.0   \n",
       "5853     tertiary      30.0   \n",
       "5854     tertiary      30.0   \n",
       "5855     tertiary      30.0   \n",
       "5856     tertiary      30.0   \n",
       "\n",
       "                                               geometry   study_area  hour  \\\n",
       "0     LINESTRING (-122.30894 47.6061773, -122.308940...  Cherry Hill     8   \n",
       "1     LINESTRING (-122.30894 47.6061773, -122.309064...  Cherry Hill     8   \n",
       "2     LINESTRING (-122.3102402 47.6080375, -122.3103...  Cherry Hill     8   \n",
       "3     LINESTRING (-122.3089518 47.6080341, -122.3096...  Cherry Hill     8   \n",
       "4     LINESTRING (-122.30894 47.6061773, -122.308940...  Cherry Hill     9   \n",
       "...                                                 ...          ...   ...   \n",
       "5852  LINESTRING (-122.316779 47.6074153, -122.31677...     12th Ave    19   \n",
       "5853  LINESTRING (-122.316779 47.6074153, -122.31677...     12th Ave    20   \n",
       "5854  LINESTRING (-122.316779 47.6074153, -122.31677...     12th Ave    21   \n",
       "5855  LINESTRING (-122.316779 47.6074153, -122.31677...     12th Ave    22   \n",
       "5856  LINESTRING (-122.316779 47.6074153, -122.31677...     12th Ave    23   \n",
       "\n",
       "      weekday  commercial_100  residential_100  transportation_100  \\\n",
       "0           3            45.0             30.0                 0.0   \n",
       "1           3            15.0              0.0                 0.0   \n",
       "2           3            75.0            105.0                 0.0   \n",
       "3           3            60.0             60.0                 0.0   \n",
       "4           3            45.0             30.0                 0.0   \n",
       "...       ...             ...              ...                 ...   \n",
       "5852        2            20.0             20.0                 0.0   \n",
       "5853        2            20.0             20.0                 0.0   \n",
       "5854        2            20.0             20.0                 0.0   \n",
       "5855        2            20.0             20.0                 0.0   \n",
       "5856        2            20.0             20.0                 0.0   \n",
       "\n",
       "      schools_100  eventsites_100  restaurant_here_100  shopping_here_100  \\\n",
       "0             0.0             0.0                    0                  0   \n",
       "1             0.0             0.0                    0                  1   \n",
       "2             0.0             0.0                    0                  0   \n",
       "3             0.0             0.0                    0                  1   \n",
       "4             0.0             0.0                    0                  0   \n",
       "...           ...             ...                  ...                ...   \n",
       "5852          0.0             0.0                    7                  1   \n",
       "5853          0.0             0.0                    7                  1   \n",
       "5854          0.0             0.0                    7                  1   \n",
       "5855          0.0             0.0                    7                  1   \n",
       "5856          0.0             0.0                    7                  1   \n",
       "\n",
       "      office_here_100  supermarket_here_100  transportation_here_100  \\\n",
       "0                   1                     0                        1   \n",
       "1                   1                     2                        2   \n",
       "2                   0                     0                        0   \n",
       "3                   0                     0                        0   \n",
       "4                   1                     0                        1   \n",
       "...               ...                   ...                      ...   \n",
       "5852                0                     1                        1   \n",
       "5853                0                     1                        1   \n",
       "5854                0                     1                        1   \n",
       "5855                0                     1                        1   \n",
       "5856                0                     1                        1   \n",
       "\n",
       "      schools_here_100  capacity  \\\n",
       "0                    0         0   \n",
       "1                    0         0   \n",
       "2                    0         0   \n",
       "3                    0         0   \n",
       "4                    0         0   \n",
       "...                ...       ...   \n",
       "5852                 0         0   \n",
       "5853                 0         0   \n",
       "5854                 0         0   \n",
       "5855                 0         0   \n",
       "5856                 0         0   \n",
       "\n",
       "                                        hourly_capacity  current_capacity  \\\n",
       "0     {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "1     {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "2     {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "3     {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "4     {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "...                                                 ...               ...   \n",
       "5852  {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5853  {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5854  {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5855  {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5856  {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "\n",
       "      num_off_street_parking_100  off_street_capa_100       time_key  tempC  \\\n",
       "0                              1                   25  2019-03-21-08     12   \n",
       "1                              1                  103  2019-03-21-08     12   \n",
       "2                              1                   15  2019-03-21-08     12   \n",
       "3                              0                    0  2019-03-21-08     12   \n",
       "4                              1                   25  2019-03-21-09     13   \n",
       "...                          ...                  ...            ...    ...   \n",
       "5852                           1                    6  2019-06-05-19     13   \n",
       "5853                           1                    6  2019-06-05-20     12   \n",
       "5854                           1                    6  2019-06-05-21     10   \n",
       "5855                           1                    6  2019-06-05-22     10   \n",
       "5856                           1                    6  2019-06-05-23      9   \n",
       "\n",
       "      windspeedKmph  precipMM  ongoing_trans  \n",
       "0                10       0.0            1.0  \n",
       "1                10       0.0            1.0  \n",
       "2                10       0.0            0.0  \n",
       "3                10       0.0            1.0  \n",
       "4                11       0.0            1.0  \n",
       "...             ...       ...            ...  \n",
       "5852             13       0.2            5.0  \n",
       "5853             10       0.0            0.0  \n",
       "5854              7       0.0            0.0  \n",
       "5855              8       0.0            0.0  \n",
       "5856              9       0.1            0.0  \n",
       "\n",
       "[5857 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Filter input data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we proved in baseline, that there are 17 areas in total but only 9 areas has a record over 250, and the rest areas are quite spreaded, therefore, we filtered out only the 9 areas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Filter data for selected areas\n",
    "selected_areas = [\n",
    "    'Greenlake',\n",
    "    'South Lake Union',\n",
    "    'Commercial Core',\n",
    "    'Pike-Pine',\n",
    "    'Uptown',\n",
    "    'Ballard',\n",
    "    'First Hill',\n",
    "    'Chinatown/ID',\n",
    "    'Pioneer Square'\n",
    "]\n",
    "train_data_with_trans_100_filtered = train_data_with_trans_100[\n",
    "    train_data_with_trans_100[\"study_area\"].isin(selected_areas)\n",
    "]\n",
    "\n",
    "street_count = len(train_data_with_trans_100_filtered.street_id.unique())\n",
    "raw_street_count_unique = len(train_data_with_trans_100.street_id.unique())\n",
    "print(f'Filtered Data Shape: {train_data_with_trans_100_filtered.shape}')\n",
    "print(f'Training data has {street_count} streets')\n",
    "print(f'Original Data without filtering has {raw_street_count_unique} unique streets (ground truth)')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filtered Data Shape: (5427, 31)\n",
      "Training data has 393 streets\n",
      "Original Data without filtering has 427 unique streets (ground truth)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_data_with_trans_100_filtered"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street_id</th>\n",
       "      <th>observation_interval_start</th>\n",
       "      <th>availability</th>\n",
       "      <th>length</th>\n",
       "      <th>highway</th>\n",
       "      <th>maxspeed</th>\n",
       "      <th>geometry</th>\n",
       "      <th>study_area</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>commercial_100</th>\n",
       "      <th>residential_100</th>\n",
       "      <th>transportation_100</th>\n",
       "      <th>schools_100</th>\n",
       "      <th>eventsites_100</th>\n",
       "      <th>restaurant_here_100</th>\n",
       "      <th>shopping_here_100</th>\n",
       "      <th>office_here_100</th>\n",
       "      <th>supermarket_here_100</th>\n",
       "      <th>transportation_here_100</th>\n",
       "      <th>schools_here_100</th>\n",
       "      <th>capacity</th>\n",
       "      <th>hourly_capacity</th>\n",
       "      <th>current_capacity</th>\n",
       "      <th>num_off_street_parking_100</th>\n",
       "      <th>off_street_capa_100</th>\n",
       "      <th>time_key</th>\n",
       "      <th>tempC</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>ongoing_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>8671</td>\n",
       "      <td>2019-04-04 08:04:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.835</td>\n",
       "      <td>secondary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3261643 47.6789845, -122.3262...</td>\n",
       "      <td>Greenlake</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-04-04-08</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>7390</td>\n",
       "      <td>2019-04-04 08:13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.163</td>\n",
       "      <td>secondary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3282649 47.6783132, -122.3280...</td>\n",
       "      <td>Greenlake</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-04-04-08</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>23879</td>\n",
       "      <td>2019-04-04 08:25:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.089</td>\n",
       "      <td>secondary</td>\n",
       "      <td>35.0</td>\n",
       "      <td>LINESTRING (-122.3406668 47.6286046, -122.3405...</td>\n",
       "      <td>South Lake Union</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>2019-04-04-08</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>21688</td>\n",
       "      <td>2019-04-04 08:26:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.891</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3245469 47.6798127, -122.3245...</td>\n",
       "      <td>Greenlake</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>2019-04-04-08</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>16023</td>\n",
       "      <td>2019-04-04 08:27:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.134</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.324689 47.6805157, -122.32492...</td>\n",
       "      <td>Greenlake</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>206</td>\n",
       "      <td>2019-04-04-08</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>980</td>\n",
       "      <td>2019-06-01 22:19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.326</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3364381 47.6065823, -122.3365...</td>\n",
       "      <td>Commercial Core</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>{'0': 2, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>771</td>\n",
       "      <td>2019-06-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>19356</td>\n",
       "      <td>2019-06-01 22:21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.617</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3368912 47.6087555, -122.3370...</td>\n",
       "      <td>Commercial Core</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>{'0': 9, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1062</td>\n",
       "      <td>2019-06-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>17924</td>\n",
       "      <td>2019-06-01 22:27:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.121</td>\n",
       "      <td>primary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.339962 47.6113492, -122.34001...</td>\n",
       "      <td>Commercial Core</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>180.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1409</td>\n",
       "      <td>2019-06-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>13357</td>\n",
       "      <td>2019-06-01 22:29:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.517</td>\n",
       "      <td>secondary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3390905 47.607833, -122.33903...</td>\n",
       "      <td>Commercial Core</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>{'0': 13, '1': 0, '2': 0, '3': 0, '4': 0, '5':...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>244</td>\n",
       "      <td>2019-06-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>13139</td>\n",
       "      <td>2019-06-01 22:37:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.434</td>\n",
       "      <td>primary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LINESTRING (-122.3398417 47.6102801, -122.3397...</td>\n",
       "      <td>Commercial Core</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>{'0': 13, '1': 0, '2': 0, '3': 0, '4': 0, '5':...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>294</td>\n",
       "      <td>2019-06-01-22</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      street_id observation_interval_start  availability   length    highway  \\\n",
       "205        8671        2019-04-04 08:04:00           1.0   68.835  secondary   \n",
       "206        7390        2019-04-04 08:13:00           1.0   58.163  secondary   \n",
       "207       23879        2019-04-04 08:25:00           0.0  181.089  secondary   \n",
       "208       21688        2019-04-04 08:26:00           0.0   78.891   tertiary   \n",
       "209       16023        2019-04-04 08:27:00           1.0   81.134   tertiary   \n",
       "...         ...                        ...           ...      ...        ...   \n",
       "5842        980        2019-06-01 22:19:00           1.0   97.326   tertiary   \n",
       "5843      19356        2019-06-01 22:21:00           1.0   98.617   tertiary   \n",
       "5844      17924        2019-06-01 22:27:00           0.0   58.121    primary   \n",
       "5845      13357        2019-06-01 22:29:00           0.0  129.517  secondary   \n",
       "5846      13139        2019-06-01 22:37:00           1.0  128.434    primary   \n",
       "\n",
       "      maxspeed                                           geometry  \\\n",
       "205       25.0  LINESTRING (-122.3261643 47.6789845, -122.3262...   \n",
       "206       25.0  LINESTRING (-122.3282649 47.6783132, -122.3280...   \n",
       "207       35.0  LINESTRING (-122.3406668 47.6286046, -122.3405...   \n",
       "208       25.0  LINESTRING (-122.3245469 47.6798127, -122.3245...   \n",
       "209       25.0  LINESTRING (-122.324689 47.6805157, -122.32492...   \n",
       "...        ...                                                ...   \n",
       "5842      25.0  LINESTRING (-122.3364381 47.6065823, -122.3365...   \n",
       "5843      25.0  LINESTRING (-122.3368912 47.6087555, -122.3370...   \n",
       "5844      25.0  LINESTRING (-122.339962 47.6113492, -122.34001...   \n",
       "5845      25.0  LINESTRING (-122.3390905 47.607833, -122.33903...   \n",
       "5846      25.0  LINESTRING (-122.3398417 47.6102801, -122.3397...   \n",
       "\n",
       "            study_area  hour  weekday  commercial_100  residential_100  \\\n",
       "205          Greenlake     8        3           128.0              0.0   \n",
       "206          Greenlake     8        3           160.0             64.0   \n",
       "207   South Lake Union     8        3            33.0             11.0   \n",
       "208          Greenlake     8        3           160.0             64.0   \n",
       "209          Greenlake     8        3            35.0             28.0   \n",
       "...                ...   ...      ...             ...              ...   \n",
       "5842   Commercial Core    22        5            60.0             30.0   \n",
       "5843   Commercial Core    22        5            30.0             60.0   \n",
       "5844   Commercial Core    22        5           180.0            240.0   \n",
       "5845   Commercial Core    22        5            30.0             60.0   \n",
       "5846   Commercial Core    22        5           120.0            150.0   \n",
       "\n",
       "      transportation_100  schools_100  eventsites_100  restaurant_here_100  \\\n",
       "205                  0.0          0.0             0.0                    3   \n",
       "206                  0.0          0.0             0.0                    2   \n",
       "207                  0.0          0.0             0.0                    2   \n",
       "208                  0.0          0.0             0.0                   14   \n",
       "209                  0.0          0.0             0.0                   12   \n",
       "...                  ...          ...             ...                  ...   \n",
       "5842                 0.0          0.0             0.0                   12   \n",
       "5843                 0.0          0.0             0.0                    9   \n",
       "5844                 0.0          0.0             0.0                   11   \n",
       "5845                 0.0          0.0             0.0                   20   \n",
       "5846                 0.0          0.0             0.0                   15   \n",
       "\n",
       "      shopping_here_100  office_here_100  supermarket_here_100  \\\n",
       "205                   0                0                     0   \n",
       "206                   0                1                     0   \n",
       "207                   0                0                     0   \n",
       "208                   4                0                     2   \n",
       "209                   3                0                     0   \n",
       "...                 ...              ...                   ...   \n",
       "5842                 15                5                     3   \n",
       "5843                  8                2                     3   \n",
       "5844                  4                1                     1   \n",
       "5845                 13                3                     2   \n",
       "5846                 24                0                     4   \n",
       "\n",
       "      transportation_here_100  schools_here_100  capacity  \\\n",
       "205                         1                 0         0   \n",
       "206                         2                 0         0   \n",
       "207                         0                 0         0   \n",
       "208                         1                 3         0   \n",
       "209                         1                 3         0   \n",
       "...                       ...               ...       ...   \n",
       "5842                        3                 0        67   \n",
       "5843                        5                 0        14   \n",
       "5844                        3                 0        24   \n",
       "5845                        1                 0        33   \n",
       "5846                        1                 0        37   \n",
       "\n",
       "                                        hourly_capacity  current_capacity  \\\n",
       "205   {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "206   {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "207   {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "208   {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "209   {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "...                                                 ...               ...   \n",
       "5842  {'0': 2, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5843  {'0': 9, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5844  {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': ...                 0   \n",
       "5845  {'0': 13, '1': 0, '2': 0, '3': 0, '4': 0, '5':...                 0   \n",
       "5846  {'0': 13, '1': 0, '2': 0, '3': 0, '4': 0, '5':...                 0   \n",
       "\n",
       "      num_off_street_parking_100  off_street_capa_100       time_key  tempC  \\\n",
       "205                            1                   20  2019-04-04-08     14   \n",
       "206                            1                   20  2019-04-04-08     14   \n",
       "207                            1                  139  2019-04-04-08     14   \n",
       "208                            1                  186  2019-04-04-08     14   \n",
       "209                            2                  206  2019-04-04-08     14   \n",
       "...                          ...                  ...            ...    ...   \n",
       "5842                           5                  771  2019-06-01-22     14   \n",
       "5843                           4                 1062  2019-06-01-22     14   \n",
       "5844                           2                 1409  2019-06-01-22     14   \n",
       "5845                           2                  244  2019-06-01-22     14   \n",
       "5846                           3                  294  2019-06-01-22     14   \n",
       "\n",
       "      windspeedKmph  precipMM  ongoing_trans  \n",
       "205               3       0.0            1.0  \n",
       "206               3       0.0            0.0  \n",
       "207               3       0.0            3.0  \n",
       "208               3       0.0            2.0  \n",
       "209               3       0.0            1.0  \n",
       "...             ...       ...            ...  \n",
       "5842              5       0.0            0.0  \n",
       "5843              5       0.0            0.0  \n",
       "5844              5       0.0            0.0  \n",
       "5845              5       0.0            0.0  \n",
       "5846              5       0.0            0.0  \n",
       "\n",
       "[5427 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Create Street as Similarity Entity - Calculate Distance Between Street Vectors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    1. Goal: understand the similarity of all the streets in seattle based on its vector representation, define the similarity between streets\n",
    "    2. Below steps have been included in this section:\n",
    "\n",
    "        1)Process the data\n",
    "        2)compute the distance(cosine, euclinean)\n",
    "        3)correlate output of the previous, correlate euclinean/cosine withh real geo distance\n",
    "        4)analyze if they are really correlated"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Preprocess Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_data_with_trans_100.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['street_id', 'observation_interval_start', 'availability', 'length',\n",
       "       'highway', 'maxspeed', 'geometry', 'study_area', 'hour', 'weekday',\n",
       "       'commercial_100', 'residential_100', 'transportation_100',\n",
       "       'schools_100', 'eventsites_100', 'restaurant_here_100',\n",
       "       'shopping_here_100', 'office_here_100', 'supermarket_here_100',\n",
       "       'transportation_here_100', 'schools_here_100', 'capacity',\n",
       "       'hourly_capacity', 'current_capacity', 'num_off_street_parking_100',\n",
       "       'off_street_capa_100', 'time_key', 'tempC', 'windspeedKmph', 'precipMM',\n",
       "       'ongoing_trans'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "hour, weekday, current_capacity, tempC, windspeedKmph, precipMM - we did not include for it to calculate the street similarity as they are time dependent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# create data\n",
    "# hour, weekday, current_capacity, tempC, windspeedKmph, precipMM - we did not include for it to calculate the street similarity as they are time dependent\n",
    "selected_features = [\n",
    "    'street_id', # note this is not as feature, but just needed to be selected\n",
    "    'availability', # note this is not as feature, but just needed to be selected\n",
    "    'length',\n",
    "    'highway',\n",
    "    'maxspeed', # input but not used for clustering\n",
    "    'commercial_100',\n",
    "    'residential_100',\n",
    "    'transportation_100',\n",
    "    'schools_100',\n",
    "    'eventsites_100',\n",
    "    'geometry',# note this is not as feature, but just needed to be selected\n",
    "    'restaurant_here_100',\n",
    "    'shopping_here_100',\n",
    "    'office_here_100',\n",
    "    'supermarket_here_100',\n",
    "    'transportation_here_100',\n",
    "    'schools_here_100',\n",
    "    'num_off_street_parking_100',\n",
    "    'off_street_capa_100',\n",
    "    'ongoing_trans'\n",
    "]\n",
    "# preprocess the data, here we use the df_similarity_features as basis to cluster the streets based on their vector\n",
    "# similarity\n",
    "df_features, df_similarity_features, _, df_geometry = \\\n",
    "    lsh.preprocess_for_similarity_analysis(\n",
    "        train_data_with_trans_100_filtered,\n",
    "        selected_features,\n",
    "        options={\n",
    "            'impute_maxspeed': False,# not use maxspeed when clustering\n",
    "            'encode_highway': True, # use highway when clustering\n",
    "            'time_dependant_features': None, # we decide not to use time_depedent feature when clustering\n",
    "        }\n",
    "    )\n",
    "\n",
    "# only take the unique streets, currently cluster only based on streets\n",
    "df_similarity_features['street_id'] = df_similarity_features.index\n",
    "df_similarity_features.drop_duplicates(subset=['street_id'], inplace=True)\n",
    "df_similarity_features.drop(['street_id'], axis=1, inplace=True)\n",
    "df_geometry = df_geometry \\\n",
    "    .drop_duplicates(subset=['street_id']) \\\n",
    "    .set_index('street_id')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/prisc/opt/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df_features.head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>availability</th>\n",
       "      <th>length</th>\n",
       "      <th>highway</th>\n",
       "      <th>maxspeed</th>\n",
       "      <th>commercial_100</th>\n",
       "      <th>residential_100</th>\n",
       "      <th>transportation_100</th>\n",
       "      <th>schools_100</th>\n",
       "      <th>eventsites_100</th>\n",
       "      <th>geometry</th>\n",
       "      <th>restaurant_here_100</th>\n",
       "      <th>shopping_here_100</th>\n",
       "      <th>office_here_100</th>\n",
       "      <th>supermarket_here_100</th>\n",
       "      <th>transportation_here_100</th>\n",
       "      <th>schools_here_100</th>\n",
       "      <th>num_off_street_parking_100</th>\n",
       "      <th>off_street_capa_100</th>\n",
       "      <th>ongoing_trans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>1.0</td>\n",
       "      <td>68.835</td>\n",
       "      <td>secondary</td>\n",
       "      <td>25.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LINESTRING (-122.3261643 47.6789845, -122.3262...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           availability  length    highway  maxspeed  commercial_100  \\\n",
       "street_id                                                              \n",
       "8671                1.0  68.835  secondary      25.0           128.0   \n",
       "\n",
       "           residential_100  transportation_100  schools_100  eventsites_100  \\\n",
       "street_id                                                                     \n",
       "8671                   0.0                 0.0          0.0             0.0   \n",
       "\n",
       "                                                    geometry  \\\n",
       "street_id                                                      \n",
       "8671       LINESTRING (-122.3261643 47.6789845, -122.3262...   \n",
       "\n",
       "           restaurant_here_100  shopping_here_100  office_here_100  \\\n",
       "street_id                                                            \n",
       "8671                         3                  0                0   \n",
       "\n",
       "           supermarket_here_100  transportation_here_100  schools_here_100  \\\n",
       "street_id                                                                    \n",
       "8671                          0                        1                 0   \n",
       "\n",
       "           num_off_street_parking_100  off_street_capa_100  ongoing_trans  \n",
       "street_id                                                                  \n",
       "8671                                1                   20            1.0  "
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop on-going transaction, as it is also time dependent feature, we do not need time-dependent feature when we have on-going trans\n",
    "df_similarity_features.drop(['ongoing_trans'], axis = 1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_similarity_features.head(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'We have used {len(df_similarity_features.columns)} features to cluster the {len(df_similarity_features)} streets.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_geometry.head(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#lsp.plot_highway(df_features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Compute the pairwise distance(euclinean, cosine) of the streets based on feature vector\n",
    "hereby we are normalizing the feature:\n",
    "\n",
    "    1)so within each feature, they have the same variation\n",
    "    2)different features have different variation\n",
    "    3)(in which case, we keep the different magnitude of the different features, namely preserved the distribution between features)"
   ],
   "metadata": {
    "lines_to_next_cell": 0
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.1 Use l2 to normalize features(columns)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To calculate the distance between the vectors, we firstly need to normalize the vectors, multiple ways are possible, and we would use L2 below to firstly normalize and then use euclidean to calculate the distance, therefore, we try out different ways and determine a way which could distinguish the streets more."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_similarity_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compute pairwise distance\n",
    "# for euclinean distance -normalize first, normalize the features NOT the rows\n",
    "similarity_features_l2_normalized = preprocessing.normalize(\n",
    "    df_similarity_features, norm='l2', axis=0)\n",
    "\n",
    "df_similarity_features_l2_normalized = pd.DataFrame(\n",
    "    similarity_features_l2_normalized,\n",
    "    index=df_similarity_features.index,\n",
    "    columns=df_similarity_features.columns\n",
    ")\n",
    "\n",
    "# call the distance function\n",
    "df_pair_dist_l2_normalized = lsh.street_pairwise_dist(\n",
    "    df_similarity_features_l2_normalized, 'euclidean')\n",
    "df_pair_cosine = lsh.street_pairwise_dist(df_similarity_features, 'cosine')\n",
    "\n",
    "# normalize enclinean distance matrix, so that it is on same scale[0, 1] with cosine to be able to compare better with correlation plot\n",
    "\n",
    "df_pair_dist_l2_normalized_scaled = lsh.scale_before_plot_correlation(\n",
    "    df_pair_dist_l2_normalized)\n",
    "\n",
    "# plot all the streets for both l2 normalized and cosine normalized distance\n",
    "# the lighhter the color, the less distant, the more similar they are\n",
    "lsp.plot_distance_matrix(\n",
    "    df_pair_dist_l2_normalized_scaled,\n",
    "    df_pair_cosine,\n",
    "    len(df_similarity_features),\n",
    "    'L2 Normalized Euclidean Distance Matrix Between Street Vectors',\n",
    "    'Cosine Distance Matrix Between Street Vectors'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.2 Use min max to normalize features(columns)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use min-max normalizer first before calculate the euclidean distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# use min max scaler\n",
    "similarity_features_max_normalized = preprocessing.normalize(\n",
    "    df_similarity_features, norm='max', axis=0)\n",
    "\n",
    "df_similarity_features_max_normalized = pd.DataFrame(\n",
    "    similarity_features_max_normalized,\n",
    "    index=df_similarity_features.index,\n",
    "    columns=df_similarity_features.columns\n",
    "\n",
    ")\n",
    "# get the euclinean distance\n",
    "df_pair_dist_max_normalized = lsh.street_pairwise_dist(\n",
    "    df_similarity_features_max_normalized, 'euclidean')\n",
    "\n",
    "# get the scaled euclinean distance, range[0,1]\n",
    "df_pair_dist_max_normalized_scaled = lsh.scale_before_plot_correlation(\n",
    "    df_pair_dist_max_normalized)\n",
    "\n",
    "lsp.plot_distance_matrix(\n",
    "    df_pair_dist_max_normalized_scaled,\n",
    "    df_pair_cosine,\n",
    "    len(df_similarity_features),\n",
    "    'Minmax Normalized Euclidean Distance Matrix Between Street Vectors',\n",
    "    'Cosine Distance Matrix Between Street Vectors'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Conclusion: the darker the color, the more 'distant' are the streets, thus they would be more distinguishable, and therefore minmax normalized euclindean distance can distinguish the streets more**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Compute the pairwise distance of the streets based on geometry"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another way to think about the distance betweent the streets are of course the geographical distance, and hereby we use the centroid of the lines as the geometry of the streets and calculate the pairwised geographical distance between the streets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the centroid\n",
    "df_geometry['geometry'] = df_geometry['geometry'].apply(wkt.loads)\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    df_geometry,\n",
    "    geometry=df_geometry['geometry']\n",
    ")\n",
    "gdf['line_centroid'] = gdf['geometry'].centroid\n",
    "gdf.head()"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = lsh.calculate_street_similarity_matrix(gdf)\n",
    "df_real_dist = pd.DataFrame(data=result)\n",
    "#df_real_dist.to_csv('df_real_dist.csv')\n",
    "#df_real_dist = pd.read_csv('df_real_dist.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.4 Correlate the distances calculated above"
   ],
   "metadata": {
    "lines_to_next_cell": 0
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal of this part is to decide which distance metrics to use to calculate the similarity based either on feature vectors of the streets or geometry of the streets, therefore, we correlated the below combinations:\n",
    "1) L2 normalized euclinean distance\n",
    "2) max normalized euclinean distance\n",
    "3) cosine distance respectively with the actual geo distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4.1 Correlation between two distance metrics (euclinean and cosine)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Correlate l2 normalized euclidean and cosine distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_l2euclinean_cosine = df_pair_dist_l2_normalized.corrwith(\n",
    "    df_pair_cosine, axis=0)\n",
    "lsp.plot_correlation_distance(corr_l2euclinean_cosine, 'Correlate L2 Normalized Euclidean and Cosine Distance')"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Correlate Minmax normalized euclidean and cosine distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_maxeuclinean_cosine = df_pair_dist_max_normalized.corrwith(\n",
    "    df_pair_cosine, axis=0)\n",
    "\n",
    "lsp.plot_correlation_distance(corr_maxeuclinean_cosine, 'Correlate Minmax Normalized Euclidean and Cosine Distance')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4.2 Correlation between the l2 or max normalized euclinean distance with the real geo distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_real_dist.index = df_real_dist.index.astype('int64', False)\n",
    "df_real_dist.columns = df_real_dist.columns.astype('int64', False)"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Correlate l2 normalized euclidean distance and real geo distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_l2euclinean_realdist = df_pair_dist_l2_normalized.corrwith(\n",
    "    df_real_dist, axis=0)\n",
    "lsp.plot_correlation_distance(corr_l2euclinean_realdist, 'Correlate L2 Normalized Euclidean and Real Geo Distance')"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Correlate min max normalized euclidean distance and real geo distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_maxeuclinean_realdist = df_pair_dist_max_normalized.corrwith(\n",
    "    pd.DataFrame(df_real_dist), axis=0)\n",
    "lsp.plot_correlation_distance(corr_maxeuclinean_realdist, 'Correlate Minmax Normalized Euclidean and Real Geo Distance')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_cosindist_realdist = df_pair_cosine.corrwith(\n",
    "    pd.DataFrame(df_real_dist), axis=0)\n",
    "lsp.plot_correlation_distance(corr_cosindist_realdist , 'Correlate Cosine Distance and Real Geo Distance')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conclusion: based on above graphs, we choose the method which correlated mostly to the real geographica distance, therefore, we decided to use min-max normalized Euclidean distance as street similarity distance metric.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Create Clusters as Similarity Entity"
   ],
   "metadata": {
    "lines_to_next_cell": 0
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After creating streets as similarity entity, we now cluster those streets, to generate similarity clusters, which is representive. We have chose several clustering algortims and also initializing the clustering two process for source and target areas separately."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. use min max normalized euclinean distance to normalize street vectors(based on above analysis)\n",
    "2. for each area combination:\n",
    "        for each type of similarity measurement (either GPS or vector similairity)\n",
    "            cluster data based on different clustering algorithm(either kmeans of ag"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 Plot the Data Points"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_geometry['lon'] = df_geometry.line_centroid.apply(lambda p: p.x)\n",
    "df_geometry['lat'] = df_geometry.line_centroid.apply(lambda p: p.y)\n",
    "\n",
    "df_geometry.head()"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get city coordinates\n",
    "\n",
    "city = \"Seattle\"\n",
    "locator = geopy.geocoders.Nominatim(user_agent=\"MyCoder\")\n",
    "location_seattle = locator.geocode(city)\n",
    "\n",
    "location_seattle = [location_seattle.latitude, location_seattle.longitude]\n",
    "print(\"[lat, long]:\", location_seattle)\n",
    "\n",
    "# map to plot the area\n",
    "df_street_coords = df_geometry[['lon', 'lat']]\n",
    "df_study_area = train_data_with_trans_100_filtered[['street_id', 'study_area']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .set_index('street_id')\n",
    "street_coords_study_area = pd.merge(\n",
    "    df_street_coords, df_study_area, left_index=True, right_index=True)\n",
    "\n",
    "street_coords_study_area['study_area'] = street_coords_study_area['study_area'].map(\n",
    "    {\n",
    "\n",
    "        'Pike-Pine': 0,\n",
    "        'First Hill': 1,\n",
    "        'South Lake Union': 2,\n",
    "        'Commercial Core': 3,\n",
    "        'Ballard': 4,\n",
    "        'Chinatown/ID': 5,\n",
    "        'Greenlake': 6,\n",
    "        'Pioneer Square': 7,\n",
    "        'University District': 8,\n",
    "        'Uptown': 9, #\n",
    "        'Uptown Triangle': 10,\n",
    "        'Capitol Hill': 11,\n",
    "        'University District': 12,\n",
    "        '12th Ave': 13,\n",
    "        'Fremont': 14,\n",
    "        'Cherry Hill': 15,\n",
    "        'Ballard Locks': 16,\n",
    "        'Roosevelt': 17,\n",
    "        'Westlake': 18,\n",
    "        'Columbia City': 19\n",
    "    }\n",
    ")\n",
    "\n",
    "# plot the map where shows the 4 districts of Seattle, the output html is called map\n",
    "#lsp.plot_cluster_folium(\n",
    "#    data=street_coords_study_area,\n",
    "#    study_area='study_area',\n",
    "#    tiles='OpenStreetMap'\n",
    "#)"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data_with_trans_100_filtered.study_area.unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'There are {len(street_coords_study_area.study_area.unique())} unique areas in seattle after filtering out areas with small number of data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we cluster the street based on the vector similairity(the triangular matrix of the vector distance) and also on GPS(based on the geometry of the streets)\n",
    "\n",
    "    1)we split the data into train and test, and initialize clustering process for train and test separately\n",
    "    2)we tried out 3 clustering algorithms to generate cluster in result\n",
    "\n",
    "The output is expected to be:\n",
    "\n",
    "    for each street, there is a number of clustering labels generated by using different clustering algorithms and different street similarity(either GPS or vector similarity)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have refered to below materials to determine the clustering algorithms:\n",
    "\n",
    "    https://datascience.stackexchange.com/questions/761/clustering-geo-location-coordinates-lat-long-pairs\n",
    "    https://community.dataiku.com/t5/Using-Dataiku-DSS/How-to-cluster-geo-points-according-to-their-pairwise-distances/m-p/2931\n",
    "    https://datascience.stackexchange.com/questions/761/clustering-geo-location-coordinates-lat-long-pairs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.1 Prepare the clustering data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for GPS, we also need to divide by the km_per_radian\n",
    "\n",
    "km_per_radian = 6371.0088"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_street_coords = pd.merge(\n",
    "    df_street_coords, df_study_area, left_index=True, right_index=True)"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_street_coords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# split train and test area to prepare for clustering\n",
    "\n",
    "all_area_combinations = create_area_combinations(selected_areas)\n",
    "\n",
    "\"\"\"\n",
    "area_input_data:\n",
    "    - first key: area_for_train\n",
    "        - second key: Source, Target\n",
    "        - second key value: dataframe with streets data inside\n",
    "\"\"\"\n",
    "area_input_data = {}\n",
    "for area_combination in all_area_combinations:\n",
    "    area_name = area_combination['Target'][0]\n",
    "    area_input_data[area_name] = {}\n",
    "    area_input_data[area_name]['Target'] = df_street_coords[df_street_coords.study_area == area_name]\n",
    "    train_street_coords_temp=[]\n",
    "    for source_area in area_combination['Source']:\n",
    "        train_street_coords_temp.append(df_street_coords[df_street_coords.study_area == source_area])\n",
    "    area_input_data[area_name]['Source'] = pd.concat(train_street_coords_temp)"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.2 Call Clustering Function & Create Cluster Result"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Loop through different similairty metrics: either sim (represents street vector similairy) or gps(represents GPS coordinates)\n",
    "    loop through the train and test data set(as we have seperate clustering process)\n",
    "        loop through different clustering algorithm\n",
    "\"\"\"\n",
    "\n",
    "#Loop through different similairty metrics\n",
    "for i, area_name in enumerate(area_input_data.keys()):\n",
    "    print(i, '====== area_name:',area_name)\n",
    "    for base in ['sim', 'gps']:\n",
    "        # loop through the train and test data set, in the end append the cluster label back to them\n",
    "        for i, data in enumerate([\n",
    "            area_input_data[area_name]['Source'],\n",
    "            area_input_data[area_name]['Target'],\n",
    "        ]):\n",
    "            is_train = i == 0 # check if it is data is training data or not\n",
    "#            for algorithm in ['db_scan', 'kmeans', 'agg_clustering']:\n",
    "            for algorithm in ['kmeans', 'agg_clustering']:\n",
    "                label = algorithm + \"_label_\" + base  # the name of the label(clustering algo + label + similarity metrics)\n",
    "                print('performing cluster labeling for', label, is_train)\n",
    "                # call the clustering algorithm to generate cluster labels\n",
    "                cluster_data = lsh.create_cluster_label(area_input_data, df_pair_dist_max_normalized,  area_name, base, algorithm, data, is_train)\n",
    "                # append the label back to its dataframe\n",
    "                data[label] = cluster_data\n",
    "\n",
    "                # number of streets in each cluster\n",
    "                result_size = data.groupby(label).size()\n",
    "                print(f'The group result of {result_size}')\n",
    "\n",
    "                # DB scan we need to check the number of outliers\n",
    "                if algorithm == 'db_scan':\n",
    "                    outlier_count = len(data[data[label] == -1])\n",
    "                    outlier_percentage = outlier_count / len(result_size) * 100\n",
    "                    print(\n",
    "                        f'Percentage of data points which has been clustered as outliers: {outlier_percentage}%')\n",
    "\n",
    "                # plot the data with folium\n",
    "                lsp.plot_cluster_folium(\n",
    "                    data=data,\n",
    "                    cluster_label=label,\n",
    "                    train=is_train\n",
    "                )\n",
    "print('DONE!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Evalution of the Result\n",
    "\n",
    "\n",
    "Steps briefly highlighted below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_col = ['kmeans_label_gps']\n",
    "\n",
    "cluster_cols = [\n",
    "    ['agg_clustering_label_gps'],\n",
    "#    ['db_scan_label_gps'],\n",
    "    ['kmeans_label_gps'],\n",
    "#    ['db_scan_label_sim'],\n",
    "    ['kmeans_label_sim'],\n",
    "    ['agg_clustering_label_sim']\n",
    "]\n",
    "\n",
    "feature_col = ['length', 'tempC', 'windspeedKmph', 'precipMM', 'highway', 'hour', 'weekday',\n",
    "               'commercial_100', 'residential_100', 'transportation_100', 'schools_100', 'eventsites_100',\n",
    "               'restaurant_here_100','shopping_here_100', 'office_here_100', 'supermarket_here_100',\n",
    "               'transportation_here_100','schools_here_100',  'current_capacity',\n",
    "               'num_off_street_parking_100',  'off_street_capa_100',  #'ongoing_trans'\n",
    "              ]\n",
    "print(f'There are in total {feature_col} features')\n",
    "\n",
    "target_col = ['availability']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the train and test data\n",
    "area_cluster_label = {}\n",
    "for area_combination in all_area_combinations:\n",
    "    area_name = area_combination['Target'][0]\n",
    "    print('processing: ', area_name)\n",
    "    area_cluster_label[area_name] = {}\n",
    "    area_cluster_label[area_name]['Target'] = train_data_with_trans_100_filtered[train_data_with_trans_100_filtered.study_area == area_name]\n",
    "    area_train_temp=[]\n",
    "    for source_area in area_combination['Source']:\n",
    "        area_train_temp.append(train_data_with_trans_100_filtered[train_data_with_trans_100_filtered.study_area == source_area])\n",
    "    area_cluster_label[area_name]['Source'] = pd.concat(area_train_temp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# this can only be run once, as we are merging the dataframe\n",
    "\"\"\"\n",
    "below block does the following:\n",
    "    1)for each area split, for each clustering algortihm, get the source and target data, by holding out one area as target are everytime\n",
    "    2)merge the cluster label generated for different streets by different clustering algorithm back to the original dataframe\n",
    "\"\"\"\n",
    "area_source_clusters = {}\n",
    "area_target_clusters = {}\n",
    "for area_combination in all_area_combinations:\n",
    "    area_name = area_combination['Target'][0]\n",
    "    print('processing: ', area_name)\n",
    "\n",
    "\n",
    "    area_input_data[area_name]['Source'] = area_input_data[area_name]['Source'].reset_index()\n",
    "    area_input_data[area_name]['Target'] = area_input_data[area_name]['Target'].reset_index()\n",
    "\n",
    "    area_source_clusters[area_name] = pd.merge(area_cluster_label[area_name]['Source'], area_input_data[area_name]['Source'], on=['street_id', 'study_area'])\n",
    "    area_target_clusters[area_name] = pd.merge(area_cluster_label[area_name]['Target'], area_input_data[area_name]['Target'], on=['street_id', 'study_area'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Below block does the following:\n",
    "    1)collect the result for model transfer \n",
    "    2)collect result for Matthew and train cluster data size correlation\n",
    "\"\"\"\n",
    "\n",
    "result_scores = {}\n",
    "area_result_matthew_size_corr = {}\n",
    "area_result_matthew_overfit = {}\n",
    "area_result_feature_importance = {}\n",
    "\n",
    "for area_combination in all_area_combinations:\n",
    "    area_name = area_combination['Target'][0]\n",
    "    print('processing area_name: ', area_name)\n",
    "\n",
    "    result_score, result_matthew_size_corr, result_matthew_overfit, result_feat_importance = lste.train_evaluate_all_approaches(\n",
    "        cluster_cols,\n",
    "        feature_col,\n",
    "        target_col,\n",
    "        area_source_clusters[area_name],\n",
    "        area_target_clusters[area_name],\n",
    "        iterations=1000\n",
    "    )\n",
    "\n",
    "    result_score_df = pd.DataFrame(result_score)\n",
    "    result_scores[area_name] = result_score_df\n",
    "\n",
    "    area_result_matthew_size_corr[area_name] = result_matthew_size_corr\n",
    "    area_result_matthew_overfit[area_name] = result_matthew_overfit\n",
    "\n",
    "    area_result_feature_importance[area_name] = result_feat_importance"
   ],
   "outputs": [],
   "metadata": {
    "lines_to_next_cell": 2
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 Result Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for area_combination in all_area_combinations:\n",
    "    area_name = area_combination['Target'][0]\n",
    "    print('area:', area_name)\n",
    "    display(result_scores[area_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the mattew for different area combinations\n",
    "matthews = {}\n",
    "for area_combination in all_area_combinations:\n",
    "    area_name = area_combination['Target'][0]\n",
    "    print('area:', area_name)\n",
    "    #display(result_scores[area_name].loc[['matthews'],:])\n",
    "    matthews[area_name] = result_scores[area_name].loc[['Matthews'],:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_matthews = pd.concat(matthews.values())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the average of matthews across different areas\n",
    "df_matthews.mean(axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_matthews.plot.box(figsize=(8, 8), ylim=(-0.3, 0.3), grid=True, yticks=(np.arange(-0.3, 0.3, step=0.1)),\n",
    "                     title='Matthews for Minimum 25 streets in one cluster')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**As we see from the boxplot above, that our clustering algorithm cannot really beat the baseline and next step we wish to investigate the feature importance and why it is the case that it cannot outperform baseline**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Analyze Why clustering method is worse than baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Is it because dataset is too small?\n",
    "\n",
    "by correlating the matthew and train cluster size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pprint.pprint(area_result_matthew_size_corr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the best performing clustering algorithm, we plot the correlation between the training data size and the matthew score on the test cluster in scatter plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dict_matthews = df_matthews.mean(axis=0).to_dict()\n",
    "# get the algorithm name which gives avg best matthews\n",
    "best_algo = [algo for algo, value in dict_matthews.items() if value == df_matthews.mean(axis=0).max()]\n",
    "#best_algo = ['kmeans_label_sim']\n",
    "print(f\"The algorithm which gives the best Matthew is {best_algo}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the correlation\n",
    "best_algo_matthew_size_corr = []\n",
    "for area, data in area_result_matthew_size_corr.items():\n",
    "    for algor, values in data.items():\n",
    "        if algor == best_algo[0]:\n",
    "            for test_cluster_no, value in values.items():\n",
    "                best_algo_matthew_size_corr.append(value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_corr = pd.DataFrame(best_algo_matthew_size_corr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_corr.plot.scatter(x='train_cluster_size',\n",
    "                          y='matthew',\n",
    "                          c='DarkBlue',\n",
    "                          figsize=(10, 8),\n",
    "                          title=('Correlation between Matthew Score of Test Cluster and the Size of Its Train '\n",
    "                                'Cluster For Best Algorithm'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**As we observe from the above plot, we could see that there is a positive correlation between the number of data points in the training cluster, and the mathew score on its matched test cluster.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_algo"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pprint.pprint(area_result_matthew_overfit)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_algo_matthew_overfit = []\n",
    "for area, data in area_result_matthew_overfit.items():\n",
    "    for algor, values in data.items():\n",
    "        if algor == best_algo[0]:\n",
    "            for label, value in values.items():\n",
    "                best_algo_matthew_overfit.append(value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_matthew_overfit = pd.DataFrame(best_algo_matthew_overfit)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_matthew_overfit"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ylim= (df_best_algo_matthew_overfit.to_numpy().min(), df_best_algo_matthew_overfit.to_numpy().max())\n",
    "df_best_algo_matthew_overfit[['train_cluster_matthew', 'valid_cluster_matthew_20', 'test_cluster_matthew']].plot.bar(\n",
    "    rot=0, \n",
    "    figsize=(18,5), \n",
    "    grid=True, \n",
    "    ylim=ylim, \n",
    "    title='Overfiting with in Training Data and Between Train and Test',\n",
    "    xlabel = 'Clusters',\n",
    "    ylabel='Matthew',\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "within_train = df_best_algo_matthew_overfit[['train_cluster_matthew_80', 'valid_cluster_matthew_20']]\n",
    "train_test = df_best_algo_matthew_overfit[['train_cluster_matthew', 'test_cluster_matthew']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### How badly does the algorithm overfit within the training data?\n",
    "\n",
    "by analyzing Matthew of model by spliting the training cluster into 80% train, 20% valid"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "overfitting within the train, as we splited train and valid, and they are in the same domain, if there is overfitting effect, then we could conclude that the algorithm works but due to overfit that it cannot demonstrate its ability."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "axes_within_train =within_train.plot.bar(\n",
    "    rot=0, \n",
    "    figsize=(10, 5), \n",
    "    ylim=ylim, \n",
    "    title='Overfit within Train Clusters by 80-20 Split',\n",
    "    grid=True,\n",
    "    xlabel = 'Clusters',\n",
    "    ylabel='Matthew'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### How badly does the algorithm overfit?\n",
    "\n",
    "by analyzing Matthew of model on training cluster and test cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here for the best clustering algorithm, we plot analysize the over fit from train to test clusters which includes overfit + domain shift between the train and test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "axes_train_test = train_test.plot.bar(\n",
    "    rot=0, \n",
    "    figsize=(10, 5), \n",
    "    ylim=ylim,\n",
    "    title='Overfit Between Train and Test Clusters',\n",
    "    grid=True,\n",
    "    xlabel = 'Clusters',\n",
    "    ylabel='Matthew',\n",
    "    color = ['green', 'red']\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**As we could conclude from above that there is a very severe overfitting when it comes to the train to test model transfer and also maybe domain shift, when it comes to within train clusters 80-20 split, the overfitting trend still exists but not so strong, therefore, we could conclude that the clustering approach could solve partially the problem of domain shift and at the same time suffers the problem of overfitting due to the very small dataset we have.**\n",
    "\n",
    "**As it seems that our clustering approach does not solve the problem of domain shift compeletely, we would like to investigate other approaches which could 1) overcome the problem of small data set and 2) also align the distribution bettween when it comes to model transfer. Therefore, we will investigate domain adaptation approaches in the other notebook**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3 Feature Importance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "for the best performing clustering algorithm, here we analyse the feature importance of per cluster for different target areas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "area_result_feature_importance['Greenlake']['agg_clustering_label_gps'][-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_algo_feature_importance = []\n",
    "\n",
    "for area, data in area_result_feature_importance.items():\n",
    "    for algo, values in data.items():\n",
    "        if algo == best_algo[0]:\n",
    "            for label, value in values.items():\n",
    "                best_algo_feature_importance.append(value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_algo_feature_importance[8]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for df in best_algo_feature_importance:\n",
    "    if df.index.name != 'Feature Id':\n",
    "        df.set_index('Feature Id', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_feat_importance = pd.concat(best_algo_feature_importance, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_feat_importance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'We have used {len(df_best_algo_feat_importance)} features to train our model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_best_algo_feat_importance.T.plot.box(figsize=(20, 8), grid=True, title='Feature Importance by Test Cluster', rot=45)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Here we have ignored for different areas, and plot the feature importance on all the test clusters regardless of the area, and test cluster label, we could see that hour and highway, and off-street capacity are two features of importance whereas transportation_100 counts has the lest feature importance**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "ef42dcf54afef0f7cb61f71439f9333daa3912a5f6e1ff705746dac98416a3b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}